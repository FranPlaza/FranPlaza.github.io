{"title":"Modelos de Deep Learning","markdown":{"yaml":{"title":"Modelos de Deep Learning","subtitle":"Descripción del curso","format":{"html":{"toc":true,"toc-location":"left","toc-depth":2,"toc-expand":2,"html-math-method":"katex","theme":"simplex"}},"lang":"es","highlight-style":"github","toc":false,"toc-title":"Contenidos","toc-expand":false,"toc-depth":2,"number-sections":true,"number-depth":2,"bibliography":"refs.bib"},"headingText":"use_python('C:/ProgramData/Anaconda3/python.exe')","containsRefs":true,"markdown":"\n\n\n```{r}\n#| echo: false\n#| warning: false\nlibrary(reticulate)\n```\n\n\n# Objetivos del curso \n\n::: {.callout-tip appearance=\"simple\" icon=false}\n- Comprender y aplicar los principios fundamentales de Deep Learning para modelar y resolver problemas complejos en diversos dominios.\n- Diseñar, entrenar y validar modelos de Deep Learning, utilizando conjuntos de datos reales y simulados, para tareas de clasificación, regresión y otras aplicaciones avanzadas.\n- Evaluar críticamente la efectividad y eficiencia de diferentes arquitecturas de redes neuronales, incluidas las redes convolucionales y recurrentes, en la solución de problemas específicos.\n-\tDesarrollar habilidades prácticas en el uso de herramientas y librerías de software de vanguardia para el Deep Learning, tales como TensorFlow, PyTorch, y/o Keras, permitiendo la simulación y experimentación con modelos complejos.\n-\tImplementar técnicas de optimización y ajuste fino para mejorar el rendimiento de los modelos de aprendizaje profundo, así como aplicar métodos para verificar y validar la precisión de los modelos desarrollados.\n:::\n\n# Programa del curso\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 1: Fundamentos del Deep Learning\n\n    1.1. Introducción al Deep Learning y su evolución histórica.\n    1.2. Principios básicos de las redes neuronales: perceptrones, perceptrones multicapa (MLP), funciones de activación, y propagación hacia adelante.\n    1.3. Entrenamiento de redes neuronales profundas: backpropagation, descenso del gradiente y ajuste de hiperparámetros. Uso de la librería Keras para facilitar la implementación de modelos.\n    1.4. Evaluación de modelos: conjuntos de entrenamiento, validación y prueba; sobreajuste y técnicas de regularización.\n    1.5. Introducción a TensorFlow, PyTorch y Keras como interfaz de alto nivel para la construcción y el entrenamiento de modelos de deep learning.\n\n[Slides](Deep_Learning_01.html){target=\"_blank\"} </br>\n[Tutorial básico de Python](Deep_Learning_01_python.html){target=\"_blank\"}\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 2: Perceptrones Multicapa (MLP) y Deep Learning\n\n    2.1. Estructura y características de los MLP: capas ocultas, nodos y profundidad.\n    2.2. Aplicaciones prácticas de los MLP en clasificación y regresión.\n    2.3. Comparación entre MLP y otros modelos de Deep Learning en términos de capacidad, complejidad y tipos de problemas a resolver.\n    2.4. Implementación de MLP para tareas de clasificación y regresión.\n    2.5. Estrategias de optimización y ajuste fino específicas para MLP.\n\n[Slides](Deep_Learning_02.html){target=\"_blank\"} </br>\n[Guía de Keras](Deep_Learning_02_guide_01.html){target=\"_blank\"} </br>\n[Ejemplo 1: Librería `neuralnet` en R](Deep_Learning_02_examples_01.html){target=\"_blank\"} </br>\n[Ejemplo 2: Librería `keras` con datos de MNIST](Deep_Learning_02_examples_02.html){target=\"_blank\"}</br>\n[Ejemplo 3: Librería `keras` para regresión con datos de automóviles](Deep_Learning_02_examples_03.html){target=\"_blank\"}\n\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 3: Redes Neuronales Convolucionales (CNNs)\n\n    3.1.\tFundamentos de las CNNs: operación de convolución, pooling y normalización.\n    3.2.\tArquitecturas de CNNs populares: LeNet, AlexNet, VGG, ResNet e Inception.\n    3.3.\tIntroducción al Transfer Learning en CNNs: cómo reutilizar modelos preentrenados para nuevas tareas.\n    3.4.\tAplicaciones de las CNNs: reconocimiento de imágenes, detección de objetos y segmentación semántica.\n    3.5.\tPrácticas con conjuntos de datos reales utilizando librerías de Deep Learning.\n    \n[Slides](Deep_Learning_03_CNN.html){target=\"_blank\"} </br>\n[Ejemplo 1: Librería `Keras` con datos `fashion-MNIST`](Deep_Learning_03_examples_01.html){target=\"_blank\"} </br>\n[Ejemplo 2: Gatos y perros](Deep_Learning_03_examples_02.html){target=\"_blank\"} </br>\n[Ejemplo 2b: Gatos y perros, la venganza](Deep_Learning_03_examples_02b.html){target=\"_blank\"}\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 4: Redes Neuronales Recurrentes (RNNs) y LSTM\n\n    4.1.\tPrincipios de las RNNs: procesamiento de secuencias y dependencias temporales.\n    4.2.\tProblemas de las RNNs: desvanecimiento y explosión del gradiente.\n    4.3.\tLSTM y GRU: soluciones al problema del desvanecimiento del gradiente.\n    4.4.\tAplicaciones de las RNNs y LSTM: procesamiento de lenguaje natural, generación de texto y análisis de series temporales.\n    4.5.\tImplementación práctica de modelos RNN y LSTM.\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 5: Introducción a Modelos Generativos\n\n    5.1.\tDiferencia entre modelos discriminativos y generativos.\n    5.2.\tConceptos básicos de Autoencoders y su aplicación en la reducción de dimensionalidad y generación de datos.\n    5.3.\tIntroducción teórica a Redes Generativas Antagónicas (GANs): fundamentos, arquitectura y aplicaciones sin implementación práctica.\n    5.4.\tDiscusión sobre el impacto de GANs en la generación de contenido y ética en la IA.\n:::\n\n# Procedimiento de evaluación\n\nA lo largo del curso, los estudiantes desarrollarán un [Proyecto aplicado]{.green} utilizando los conocimientos adquiridos durante el curso. Los estudiantes seleccionarán un problema real para aplicar técnicas de Deep Learning, incluyendo el diseño e implementación de uno o varios modelos. \n\n::: {.callout-tip appearance=\"simple\" icon=false}\n[Presentación de proyectos:]{.green}</br>\nLos estudiantes expondrán sus proyectos (máximo 3 integrantes), mostrando la metodología, resultados y aprendizajes clave. Dicho trabajo grupal tendrá 3 presentaciones de avance ([PA]{.green}) y un informe final ([IF]{.green}), con las siguientes ponderaciones:\n\n  - PA$_1$: 25$\\%$: 9 de mayo 2024\n  - PA$_2$: 25$\\%$: 13 de Junio 2024\n  - PA$_3$: 25$\\%$: 11 de Julio 2024\n  - IF: 25$\\%$: 18 de Julio 2024\n:::\n\n# Asistencia\n\n::: {.callout-tip appearance=\"simple\" icon=false}\n[Asistencia:]{.green} 75$\\%$\n:::\n\n# Bibliografía del curso\n\nLos principales libros que usaremos, además de otros recursos online son los siguientes:\n\n::: {layout-ncol=4}\n![@Goodfellow2016, [Disponible acá](https://www.deeplearningbook.org/)](images/Book_deep_learning.png){height=250px}\n\n![@Geron2022, con su repositorio gratuito en [GitHub](https://github.com/ageron/handson-ml3) ](images/Book_Hands_on_ML.jpg){height=250px}\n\n![@Raschka2019, con su repositorio gratuito en [GitHub](https://github.com/rasbt/python-machine-learning-book-3rd-edition)](images/Book_Machine_Learning.jpg){height=250px}\n\n![@Zhang2023, [Disponible acá](https://d2l.ai/)](images/Book_Dive_DL.jpg){height=250px}\n:::\n\n# Referencias\n\n::: {#refs}\n:::\n","srcMarkdownNoYaml":"\n\n\n```{r}\n#| echo: false\n#| warning: false\nlibrary(reticulate)\n# use_python('C:/ProgramData/Anaconda3/python.exe')\n```\n\n\n# Objetivos del curso \n\n::: {.callout-tip appearance=\"simple\" icon=false}\n- Comprender y aplicar los principios fundamentales de Deep Learning para modelar y resolver problemas complejos en diversos dominios.\n- Diseñar, entrenar y validar modelos de Deep Learning, utilizando conjuntos de datos reales y simulados, para tareas de clasificación, regresión y otras aplicaciones avanzadas.\n- Evaluar críticamente la efectividad y eficiencia de diferentes arquitecturas de redes neuronales, incluidas las redes convolucionales y recurrentes, en la solución de problemas específicos.\n-\tDesarrollar habilidades prácticas en el uso de herramientas y librerías de software de vanguardia para el Deep Learning, tales como TensorFlow, PyTorch, y/o Keras, permitiendo la simulación y experimentación con modelos complejos.\n-\tImplementar técnicas de optimización y ajuste fino para mejorar el rendimiento de los modelos de aprendizaje profundo, así como aplicar métodos para verificar y validar la precisión de los modelos desarrollados.\n:::\n\n# Programa del curso\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 1: Fundamentos del Deep Learning\n\n    1.1. Introducción al Deep Learning y su evolución histórica.\n    1.2. Principios básicos de las redes neuronales: perceptrones, perceptrones multicapa (MLP), funciones de activación, y propagación hacia adelante.\n    1.3. Entrenamiento de redes neuronales profundas: backpropagation, descenso del gradiente y ajuste de hiperparámetros. Uso de la librería Keras para facilitar la implementación de modelos.\n    1.4. Evaluación de modelos: conjuntos de entrenamiento, validación y prueba; sobreajuste y técnicas de regularización.\n    1.5. Introducción a TensorFlow, PyTorch y Keras como interfaz de alto nivel para la construcción y el entrenamiento de modelos de deep learning.\n\n[Slides](Deep_Learning_01.html){target=\"_blank\"} </br>\n[Tutorial básico de Python](Deep_Learning_01_python.html){target=\"_blank\"}\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 2: Perceptrones Multicapa (MLP) y Deep Learning\n\n    2.1. Estructura y características de los MLP: capas ocultas, nodos y profundidad.\n    2.2. Aplicaciones prácticas de los MLP en clasificación y regresión.\n    2.3. Comparación entre MLP y otros modelos de Deep Learning en términos de capacidad, complejidad y tipos de problemas a resolver.\n    2.4. Implementación de MLP para tareas de clasificación y regresión.\n    2.5. Estrategias de optimización y ajuste fino específicas para MLP.\n\n[Slides](Deep_Learning_02.html){target=\"_blank\"} </br>\n[Guía de Keras](Deep_Learning_02_guide_01.html){target=\"_blank\"} </br>\n[Ejemplo 1: Librería `neuralnet` en R](Deep_Learning_02_examples_01.html){target=\"_blank\"} </br>\n[Ejemplo 2: Librería `keras` con datos de MNIST](Deep_Learning_02_examples_02.html){target=\"_blank\"}</br>\n[Ejemplo 3: Librería `keras` para regresión con datos de automóviles](Deep_Learning_02_examples_03.html){target=\"_blank\"}\n\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 3: Redes Neuronales Convolucionales (CNNs)\n\n    3.1.\tFundamentos de las CNNs: operación de convolución, pooling y normalización.\n    3.2.\tArquitecturas de CNNs populares: LeNet, AlexNet, VGG, ResNet e Inception.\n    3.3.\tIntroducción al Transfer Learning en CNNs: cómo reutilizar modelos preentrenados para nuevas tareas.\n    3.4.\tAplicaciones de las CNNs: reconocimiento de imágenes, detección de objetos y segmentación semántica.\n    3.5.\tPrácticas con conjuntos de datos reales utilizando librerías de Deep Learning.\n    \n[Slides](Deep_Learning_03_CNN.html){target=\"_blank\"} </br>\n[Ejemplo 1: Librería `Keras` con datos `fashion-MNIST`](Deep_Learning_03_examples_01.html){target=\"_blank\"} </br>\n[Ejemplo 2: Gatos y perros](Deep_Learning_03_examples_02.html){target=\"_blank\"} </br>\n[Ejemplo 2b: Gatos y perros, la venganza](Deep_Learning_03_examples_02b.html){target=\"_blank\"}\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 4: Redes Neuronales Recurrentes (RNNs) y LSTM\n\n    4.1.\tPrincipios de las RNNs: procesamiento de secuencias y dependencias temporales.\n    4.2.\tProblemas de las RNNs: desvanecimiento y explosión del gradiente.\n    4.3.\tLSTM y GRU: soluciones al problema del desvanecimiento del gradiente.\n    4.4.\tAplicaciones de las RNNs y LSTM: procesamiento de lenguaje natural, generación de texto y análisis de series temporales.\n    4.5.\tImplementación práctica de modelos RNN y LSTM.\n:::\n\n::: {.callout-tip collapse=\"true\" icon=false}\n## Unidad 5: Introducción a Modelos Generativos\n\n    5.1.\tDiferencia entre modelos discriminativos y generativos.\n    5.2.\tConceptos básicos de Autoencoders y su aplicación en la reducción de dimensionalidad y generación de datos.\n    5.3.\tIntroducción teórica a Redes Generativas Antagónicas (GANs): fundamentos, arquitectura y aplicaciones sin implementación práctica.\n    5.4.\tDiscusión sobre el impacto de GANs en la generación de contenido y ética en la IA.\n:::\n\n# Procedimiento de evaluación\n\nA lo largo del curso, los estudiantes desarrollarán un [Proyecto aplicado]{.green} utilizando los conocimientos adquiridos durante el curso. Los estudiantes seleccionarán un problema real para aplicar técnicas de Deep Learning, incluyendo el diseño e implementación de uno o varios modelos. \n\n::: {.callout-tip appearance=\"simple\" icon=false}\n[Presentación de proyectos:]{.green}</br>\nLos estudiantes expondrán sus proyectos (máximo 3 integrantes), mostrando la metodología, resultados y aprendizajes clave. Dicho trabajo grupal tendrá 3 presentaciones de avance ([PA]{.green}) y un informe final ([IF]{.green}), con las siguientes ponderaciones:\n\n  - PA$_1$: 25$\\%$: 9 de mayo 2024\n  - PA$_2$: 25$\\%$: 13 de Junio 2024\n  - PA$_3$: 25$\\%$: 11 de Julio 2024\n  - IF: 25$\\%$: 18 de Julio 2024\n:::\n\n# Asistencia\n\n::: {.callout-tip appearance=\"simple\" icon=false}\n[Asistencia:]{.green} 75$\\%$\n:::\n\n# Bibliografía del curso\n\nLos principales libros que usaremos, además de otros recursos online son los siguientes:\n\n::: {layout-ncol=4}\n![@Goodfellow2016, [Disponible acá](https://www.deeplearningbook.org/)](images/Book_deep_learning.png){height=250px}\n\n![@Geron2022, con su repositorio gratuito en [GitHub](https://github.com/ageron/handson-ml3) ](images/Book_Hands_on_ML.jpg){height=250px}\n\n![@Raschka2019, con su repositorio gratuito en [GitHub](https://github.com/rasbt/python-machine-learning-book-3rd-edition)](images/Book_Machine_Learning.jpg){height=250px}\n\n![@Zhang2023, [Disponible acá](https://d2l.ai/)](images/Book_Dive_DL.jpg){height=250px}\n:::\n\n# Referencias\n\n::: {#refs}\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-in-header":[{"text":"<style>\n.quarto-title-block .quarto-title-banner {\n  flex-direction: row;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  height: 400px;\n  z-index: 2;\n  padding: 0 ;\n  background-image: \n  /* top, transparent red */\n      linear-gradient(\n          rgba(100, 100, 100, 0.8), \n          rgba(100, 100, 100, 0.8)\n          ),\n          url(images/dmcc.png);\n  background-repeat: no-repeat;\n  background-position: center;\n  background-size: cover;\n  }\n .quarto-title-block .quarto-title-banner::before {\n  content: '';\n  background-image: url(images/fran.jpg);\n  background-repeat: no-repeat;\n  background-position: center;\n  background-size: contain;\n  width: 300px;\n  height: 300px;\n  margin-right: 20px;\n}\n.quarto-title-block .quarto-title-banner h1.title {\n  margin: 0;\n  text-align: left;\n  font-size: 2.5em;\n}\n</style>\n"},{"text":"<style>\n.quarto-title-block .quarto-title-banner {\n  height: 200px;\n  background-image: \n  /* top, transparent gray */\n      linear-gradient(\n          rgba(131, 131, 131, 0.8), \n          rgba(131, 131, 131, 0.8)\n          ),\n          url(cover.png);\n  background-repeat: no-repeat;\n  background-position: center;\n  background-size: cover;\n  }\n .quarto-title-block .quarto-title-banner::before {\n  content: '';\n  background-image: none;\n  background-repeat: no-repeat;\n  background-position: center;\n  background-size: contain;\n  width: 0px;\n  height: 0px;\n  margin-right: 0px;\n}\n</style>\n"}],"toc":true,"highlight-style":"github","toc-depth":2,"number-sections":true,"html-math-method":"katex","output-file":"Deep_Learning_00_About.html"},"language":{"toc-title-document":"Tabla de contenidos","toc-title-website":"En esta página","related-formats-title":"Otros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fuente","other-links-title":"Otros Enlaces","code-links-title":"Enlaces de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Cuaderno de Artículo","notebook-preview-download":"Descargar Cuaderno","notebook-preview-download-src":"Descargar código fuente","notebook-preview-back":"Volver al Artículo","manuscript-meca-bundle":"Archivo MECA","section-title-abstract":"Resumen","section-title-appendices":"Apéndices","section-title-footnotes":"Notas","section-title-references":"Referencias","section-title-reuse":"Reutilización","section-title-copyright":"Derechos de autor","section-title-citation":"Cómo citar","appendix-attribution-cite-as":"Por favor, cita este trabajo como:","appendix-attribution-bibtex":"BibTeX","title-block-author-single":"Autor/a","title-block-author-plural":"Autores/as","title-block-affiliation-single":"Afiliación","title-block-affiliation-plural":"Afiliaciones","title-block-published":"Fecha de publicación","title-block-modified":"Fecha de modificación","title-block-keywords":"Palabras clave","callout-tip-title":"Tip","callout-note-title":"Nota","callout-warning-title":"Advertencia","callout-important-title":"Importante","callout-caution-title":"Precaución","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar todo el código","code-tools-hide-all-code":"Ocultar todo el código","code-tools-view-source":"Ver el código fuente","code-tools-source-code":"Ejecutar el código","tools-share":"Compartir","tools-download":"Descargar","code-line":"Línea","code-lines":"Líneas","copy-button-tooltip":"Copiar al portapapeles","copy-button-tooltip-success":"Copiado","repo-action-links-edit":"Editar esta página","repo-action-links-source":"Ver el código","repo-action-links-issue":"Informar de un problema","back-to-top":"Volver arriba","search-no-results-text":"Sin resultados","search-matching-documents-text":"documentos encontrados","search-copy-link-title":"Copiar el enlace en la búsqueda","search-hide-matches-text":"Ocultar resultados adicionales","search-more-match-text":"resultado adicional en este documento","search-more-matches-text":"resultados adicionales en este documento","search-clear-button-title":"Borrar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Buscar","toggle-section":"Alternar sección","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo oscuro","toggle-reader-mode":"Alternar modo lector","toggle-navigation":"Navegación de palanca","crossref-fig-title":"Figura","crossref-tbl-title":"Tabla","crossref-lst-title":"Listado","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolario","crossref-prp-title":"Proposición","crossref-cnj-title":"Conjetura","crossref-def-title":"Definición","crossref-exm-title":"Ejemplo","crossref-exr-title":"Ejercicio","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apéndice","crossref-sec-prefix":"Sección","crossref-eq-prefix":"Ecuación","crossref-lof-title":"Listado de Figuras","crossref-lot-title":"Listado de Tablas","crossref-lol-title":"Listado de Listados","environment-proof-title":"Prueba","environment-remark-title":"Observación","environment-solution-title":"Solución","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Por defecto","listing-page-order-by-date-asc":"Menos reciente","listing-page-order-by-date-desc":"Más reciente","listing-page-order-by-number-desc":"De mayor a menor","listing-page-order-by-number-asc":"De menor a mayor","listing-page-field-date":"Fecha","listing-page-field-title":"Título","listing-page-field-description":"Descripción","listing-page-field-author":"Autor/a","listing-page-field-filename":"Nombre de archivo","listing-page-field-filemodified":"Fecha de modificación","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tiempo de lectura","listing-page-field-wordcount":"Conteo de Palabras","listing-page-field-categories":"Categorías","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Todas","listing-page-no-matches":"No hay resultados","listing-page-words":"{0} palabras"},"metadata":{"lang":"es","fig-responsive":true,"quarto-version":"1.4.551","title-block-banner":"#00000000","title-block-banner-color":"rgba(255, 255, 255, 0.9)","theme":{"light":["yeti","../../custom_light.css"],"dark":["yeti","../../custom_dark.css"]},"title":"Modelos de Deep Learning","subtitle":"Descripción del curso","toc-title":"Contenidos","toc-expand":2,"number-depth":2,"bibliography":["refs.bib"],"toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}