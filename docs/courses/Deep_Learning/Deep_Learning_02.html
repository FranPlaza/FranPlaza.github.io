<!DOCTYPE html>
<html lang="es"><head>
<script src="Deep_Learning_02_files/libs/clipboard/clipboard.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/tabby.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/popper.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Deep_Learning_02_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Deep_Learning_02_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.551">

  <meta name="author" content="Francisco Plaza Vega">
  <title>Deep Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/theme/quarto.css">
  <link href="Deep_Learning_02_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Deep_Learning_02_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Deep Learning</h1>
  <p class="subtitle">Unidad 2: Perceptrones Multicapa (MLP) y Deep Learning</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Francisco Plaza Vega 
</div>
<div class="quarto-title-author-email">
<a href="mailto:francisco.plaza.v@usach.cl">francisco.plaza.v@usach.cl</a>
</div>
        <p class="quarto-title-affiliation">
            Ingeniería en Estadística
          </p>
    </div>
</div>

</section>
<section>
<section id="redes-neuronales" class="title-slide slide level1 center" data-background-color="#00A499" data-number="1">
<h1><span class="header-section-number">1</span> Redes Neuronales</h1>

</section>
<section class="slide level2">

<div class="definition">
<ul>
<li class="fragment"><p>Una <span class="green">red neuronal artificial, <strong>ANN</strong></span> por sus siglas en inglés <span class="green"><em>artificial neural network</em></span> modelan la relación entre un conjunto de <span class="orange"><em>señales</em> de entrada</span> y una <span class="orange"><em>señal de salida</em></span> usando un modelo derivado desde nuestro entendimiento de cómo funciona un cerebro biológico ante estimulos externos.</p></li>
<li class="fragment"><p>Tal como un cerebro usa una red de células interconectadas llamadas <strong>neuronas</strong>, una <strong>red neuronal</strong> usa una red de neuronas artificiales o <strong>nodos</strong> para resolver problemas de aprendizaje.</p></li>
</ul>
</div>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/02_DNN/neuron.png"></p>
<figcaption>Neuronas biológicas</figcaption>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/02_DNN/neuron_in_out.png"></p>
<figcaption>Impulso nervioso</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La forma más común de representar la estructura de una red neuronal es mediante el uso de capas (<strong>layers</strong>), formadas a su vez por neuronas.</p></li>
<li class="fragment"><p>Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es refular la información que se propaga de una neurona a otra.</p></li>
</ul>
</section>
<section class="slide level2">


<img data-src="images/02_DNN/DL_infinite_layers.png" class="r-stretch quarto-figure-center"><p class="caption">Red neuronal artificial</p></section>
<section class="slide level2">

<p>Para facilitar la comprensión de la estructura de las redes, es útil representar <span class="green">una red equivalente a un modelo de regresión lineal</span>:</p>
<p><span class="math display">\[y=w_1 x_1 +\dots+w_d x_d + b\]</span></p>
<ul>
<li class="fragment"><p>Cada neurona de la capa de entrada representa el<span class="green">valor de uno de los predictores</span>.</p></li>
<li class="fragment"><p>Las flechas representan los <span class="green">coeficientes de regresión</span>, que en términos de redes se llaman <span class="orange">pesos</span>, y la neurona de salida representa el <span class="orange">valor predicho</span>.</p></li>
<li class="fragment"><p>Para que esta representación equivalga a la ecuación de un modelo lineal, faltan dos cosas:</p>
<ul>
<li class="fragment"><p>El <span class="green">sesgo (bias)</span> del modelo</p></li>
<li class="fragment"><p>Las operaciones de <span class="green">multiplicación y suma</span> que combinan el valor de los predictores con los pesos del modelo</p></li>
</ul></li>
<li class="fragment"><p>Cada neurona de la capa intermedia tiene un valor de bias, pero suele omitirse en las representaciones gráficas.</p></li>
<li class="fragment"><p>En cuanto a las operaciones matemáticas, es el elemento clave que ocurre dentro de las neuronas y conviene verlo con detalle.</p></li>
</ul>
</section></section>
<section>
<section id="neurona" class="title-slide slide level1 center" data-background-color="#00A499" data-number="2">
<h1><span class="header-section-number">2</span> Neurona</h1>

</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La neurona es la unidad funcional de los modelos de redes. Dentro de cada neurona ocurren simplemente dos operaciones: la <span class="green">suma ponderada de sus entradas</span> y la aplicación de una <span class="green">función de activación</span>.</p></li>
<li class="fragment"><p>En la primera parte, se multiplica cada valor de entrada <span class="math inline">\(x_i\)</span> por su peso asociado <span class="math inline">\(w_i\)</span> y se suman junto con el sesgo. Este es el valor neto de entrada a la neurona. A continuación, este valor se pasa por una función, conocida como <span class="orange"><strong>función de activación</strong>, que transforma el valor neto de entrada en un valor de salida</span>.</p></li>
<li class="fragment"><p>Si bien el valor que llega a la neurona, siempre es una combinación lineal, gracias a la función de activación, se pueden generar salidas muy diversas. Es en la <span class="orange">función de activación donde reside el potencial de los modelos de redes para aprender relaciones no lineales</span>.</p></li>
</ul>
</section>
<section class="slide level2">


<img data-src="images/02_DNN/neurona.png" class="r-stretch quarto-figure-center"><p class="caption">Neurona</p></section>
<section class="slide level2">

<p>Lo anterior es la noción intuitiva de las redes neuronales artificiales, en términos mátemáticos:</p>
<div class="small">
<ul>
<li class="fragment">El valor neto de entrada a una neurona es la suma de los valores que le llegan, ponderados por el peso de las conexiones, más el sesgo:</li>
</ul>
<p><span class="math display">\[Input = \sum_{i=1}^{n} x_i w_i + b\]</span></p>
<ul>
<li class="fragment">En lugar de utilizar la sumatoria, este operación usualmente se presenta como un producto matricial, donde <span class="math inline">\(X\)</span> representa el vector de los valores de entrada y <span class="math inline">\(W\)</span> el vector de pesos:</li>
</ul>
<p><span class="math display">\[Input = XW + b\]</span></p>
</div>
</section>
<section class="slide level2">

<p>A este valor se le aplica una <span class="green">función de activación <span class="math inline">\(g\)</span></span> que lo transforma en lo que se conoce como el <span class="orange">valor de activación <span class="math inline">\(a\)</span></span>, que es lo que finalmente sale de la neurona.</p>
<p><span class="math display">\[a=g(Input)=g(XW+b)\]</span></p>
<ul>
<li class="fragment"><p>Para la capa de entrada, donde únicamente se quiere incorporar el valor de los predictores, la <span class="orange">función de activación es la unidad</span>, es decir, sale lo mismo que entra.</p></li>
<li class="fragment"><p>En la capa de salida, la función de activación utilizada <span class="green">suele ser la identidad para problemas de regresión</span>, mientras que en <span class="green">problemas de clasificación, se aplican otras funciones</span>.</p></li>
</ul>
</section></section>
<section>
<section id="función-de-activación" class="title-slide slide level1 center" data-background-color="#00A499" data-number="3">
<h1><span class="header-section-number">3</span> Función de activación</h1>

</section>
<section class="slide level2">

<div class="definition">
<ul>
<li class="fragment"><p>Las funciones de activación controlan en gran medida qué información se propaga desde una capa a la siguiente (<span class="green"><em>forward propagation</em></span>).</p></li>
<li class="fragment"><p>Estas funciones convierten el valor neto de entrada a la neurona (combinación de los input, pesos y sesgo) en un nuevo valor. Gracias a combinar <span class="orange"><strong>funciones de activación no lineales con múltiples capas</strong></span>, los modelos de redes son capaces de aprender relaciones <span class="orange"><strong>no lineales</strong></span>.</p></li>
<li class="fragment"><p>La gran mayoría de funciones de activación <span class="green">convierten el valor de entrada neto de la neurona en un valor dentro del rango <span class="math inline">\((0, 1)\)</span> o <span class="math inline">\((-1, 1)\)</span></span>. Cuando el valor de activación de una neurona (salida de su función de activación) es cero, <span class="green">se dice que la neurona está <strong>inactiva</strong></span>, ya que no pasa ningún tipo de información a las siguientes neuronas.</p></li>
</ul>
</div>
</section>
<section id="tipos-de-funciones-de-activación" class="slide level2" data-number="3.1">
<h2><span class="header-section-number">3.1</span> Tipos de funciones de activación</h2>
<p>Existen <span class="green">muchas funciones de activación</span> utilizadas en la práctica, en lo que sigue mencionamos sólo algunas de ellas:</p>
<div class="small">
<ul>
<li class="fragment"><p>Sigmoide</p></li>
<li class="fragment"><p>Tangente hiperbólica</p></li>
<li class="fragment"><p><em>Rectified Linear Unit</em> (ReLU)</p></li>
<li class="fragment"><p><em>Gaussian Error Linear Unit</em> (GELU)</p></li>
<li class="fragment"><p>También hay otras como: función lineal, gaussiana, linear saturada, etc.</p></li>
</ul>
</div>
</section>
<section class="slide level2">

<h3 data-number="3.1.1" id="sigmoide"><span class="header-section-number">3.1.1</span> Sigmoide</h3>
<div class="definition">
<p>La función sigmoide transforma valores en la recta real a valores en el rango <span class="math inline">\([0, 1]\)</span>:</p>
<p><span class="math display">\[sigmoid(x)=\dfrac{1}{1+\exp(-x)}\]</span></p>
</div>

<img data-src="images/02_DNN/sigmoid.png" class="r-stretch quarto-figure-center"><p class="caption">Sigmoid</p></section>
<section class="slide level2">

<ul>
<li class="fragment"><p>Aunque la función de activación sigmoide <span class="orange">se utilizó mucho en los inicios</span> de los modelos de redes, en la actualidad, suele preferirse la función ReLU.</p></li>
<li class="fragment"><p>Un caso en el que la función de activación sigmoide sigue siendo la función utilizada por defecto es en las neuronas de la capa de salida de los <span class="orange">modelos de clasificación binaria</span>, ya que su salida puede interpretarse como probabilidad.</p></li>
</ul>
</section>
<section class="slide level2">

<h3 data-number="3.1.2" id="tangente-hiperbólica"><span class="header-section-number">3.1.2</span> Tangente hiperbólica</h3>
<div class="definition">
<p>La función de activación <code>Tanh</code>, se comporta de forma similar a la función sigmoide, pero su salida está acotada en el rango <span class="math inline">\([-1, 1]\)</span>:</p>
<p><span class="math display">\[\tanh(x)=\dfrac{1-\exp(-2x)}{1+\exp(-2x)}\]</span></p>
</div>

<img data-src="images/02_DNN/tanh.png" class="r-stretch quarto-figure-center"><p class="caption">Tangente hiperbólica</p></section>
<section class="slide level2">

<h3 data-number="3.1.3" id="rectified-linear-unit-relu"><span class="header-section-number">3.1.3</span> Rectified linear unit (ReLU)</h3>
<div class="definition">
<p>La función de activación <code>ReLu</code> aplica una transformación no lineal muy simple, <span class="green">activa la neurona solo si el input está por encima de cero</span>. Mientras el valor de entrada está por debajo de cero, el valor de salida es cero, pero cuando es superior, el valor de salida aumenta de forma lineal con el de entrada.</p>
<p><span class="math display">\[ReLU(x)=\max (0,x)\]</span></p>
</div>

<img data-src="images/02_DNN/relu.png" class="r-stretch quarto-figure-center"><p class="caption">Rectified linear unit</p></section>
<section class="slide level2">

<ul>
<li class="fragment"><p>De esta forma, la función de activación <span class="orange">retiene únicamente los valores positivos</span> y descarta los negativos dándoles una activación de cero.</p></li>
<li class="fragment"><p>ReLU es con diferencia la <span class="orange">función de activación más empleada</span> por sus buenos resultados en aplicaciones diversas. La razón de esto reside en el comportamiento de su derivada (gradiente), que es cero o constante.</p></li>
</ul>
</section>
<section class="slide level2">

<h3 data-number="3.1.4" id="gaussian-error-linear-unit-gelu"><span class="header-section-number">3.1.4</span> Gaussian Error Linear Unit (GELU)</h3>
<div class="definition">
<p>Se considera una <span class="green">mejora sobre las funciones de activación tradicionales</span> como ReLU, debido a sus propiedades suaves y no lineales.</p>
<p><span class="math display">\[ GELU(x) = x \cdot \Phi (x)\]</span> donde <span class="math inline">\(Phi(x)\)</span> representa la CDF de la distribución normal estándar.</p>
</div>

<img data-src="images/02_DNN/GELU.png" class="r-stretch quarto-figure-center"><p class="caption">Gaussian Error Linear Unit</p></section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La GELU permite que las señales pasen a través de ella de manera similar a ReLU, pero con una <span class="orange">transición más suave</span>.</p></li>
<li class="fragment"><p>En lugar de cortar directamente en cero como en ReLU (donde todos los valores negativos se convierten en cero), la GELU modula la señal de manera que los <span class="orange">valores pequeños se atenúan gradualmente</span> hacia cero, y los <span class="orange">valores positivos pasan con una transformación</span> similar a la normal.</p></li>
<li class="fragment"><p>La función GELU se ha vuelto <span class="orange">popular en modelos de deep learning avanzados</span>, como modelos de procesamiento de lenguaje natural, GAN, <a href="https://www.sciencedirect.com/science/article/pii/S2666651022000146">Transformers</a>, entre otros.</p></li>
</ul>
</section>
<section class="slide level2">

<h3 data-number="3.1.5" id="funciones-de-activación-y-sus-usos"><span class="header-section-number">3.1.5</span> Funciones de activación y sus usos</h3>
<div class="r-stack">
<p><img data-src="images/02_DNN/activation_functions_eq.png" class="fragment"></p>
<p><img data-src="images/02_DNN/activation_functions_use.png" class="fragment"></p>
</div>
</section>
<section class="slide level2">


<img data-src="images/02_DNN/activations.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplos de perceptrones y funciones de activación</p></section></section>
<section>
<section id="función-de-coste-loss-function" class="title-slide slide level1 center" data-background-color="#00A499" data-number="4">
<h1><span class="header-section-number">4</span> Función de coste (loss function)</h1>

</section>
<section class="slide level2">

<div class="definition">
<div>
<ul>
<li><p>El objetivo del modelo es <span class="green">predecir un valor real</span> o <span class="green">clasificar datos</span>.</p></li>
<li><p>Existirán <span class="orange">errores en la predicción</span>.</p></li>
<li><p>Para la <span class="orange">cuantificación de dicho error</span>, utilizaremos una <span class="green">función de coste (o pérdida)</span>.</p></li>
</ul>
</div>
</div>
<p><br></p>
<div class="fragment">
<div class="definition">
<p><span class="blue">Definición</span><br></p>
<p>Dado un set de datos <span class="math inline">\(D(\mathbf{X}, \mathbf{Y})\)</span>, con <span class="math inline">\(N\)</span> puntos y un modelo <span class="math inline">\(M\)</span>, una función general de coste está dada por</p>
<p><span class="math display">\[L(M) = \sum_{i=1}^{N} d\left[ f(x(i);M), y(i) \right]\]</span></p>
<p>con <span class="math inline">\(d[\cdot]\)</span> la distancia entre los valores predichos y los verdaderos, <span class="math inline">\(x(i)\)</span> los <span class="math inline">\(i\)</span>-ésimos valores o clases predichas y <span class="math inline">\(y(i)\)</span> los <span class="math inline">\(i\)</span>-ésimos valores o clases verdaderas.</p>
</div>
</div>
</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La <span class="green">función de coste (<span class="math inline">\(l\)</span>)</span>, también llamada función de pérdida, <span class="green"><em>loss function</em> o <em>cost function</em></span>, es la encargada de <span class="orange"><strong>cuantificar</strong> la distancia entre el valor real y el valor predicho</span> por la red, en otras palabras, <strong>mide cuánto se equivoca la red al realizar predicciones</strong>.</p></li>
<li class="fragment"><p>En la mayoría de casos, la función de coste devuelve valores positivos. <span class="green">Cuanto más próximo a cero es el valor de coste, mejor son las predicciones</span> de la red (menor error), siendo cero cuando las predicciones se corresponden exactamente con el valor real.</p></li>
</ul>

<img data-src="images/02_DNN/goals.png" class="r-stretch quarto-figure-center"><p class="caption">Distintos objetivos de un modelo.</p></section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La función de coste <span class="green">puede calcularse para una única observación o para un conjunto de datos (normalmente promediando el valor de todas las observaciones)</span>. Es el segundo caso el que se utiliza para dirigir el entrenamiento de los modelos.</p></li>
<li class="fragment"><p>Dependiendo del tipo de problema, regresión o clasificación, es necesario utilizar una función de coste u otra. En problemas de <span class="orange">regresión, las más utilizadas son el error cuadrático medio y el error absoluto medio</span>. En problemas de [clasificación suele emplearse la función <em>log loss</em>, también llamada <em>logistic loss</em> o <em>cross-entropy loss</em>]{orange}.</p></li>
</ul>
</section>
<section id="funciones-de-coste-para-regresión" class="slide level2" data-number="4.1">
<h2><span class="header-section-number">4.1</span> Funciones de coste para regresión</h2>
<div class="alert">
<p>Las funciones de coste más comunes para regresión:</p>
<div class="small">
<ul>
<li class="fragment">Error cuadrático medio:</li>
</ul>
<p><span class="math display">\[L_{sq}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}\left( \widehat{y}^{(i)}-y^{(i)}\right)^{2}\]</span></p>
<ul>
<li class="fragment">Error medio absoluto:</li>
</ul>
<p><span class="math display">\[L_{abs}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}|\widehat{y}^{(i)}-y^{(i)}|\]</span></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 data-number="4.1.1" id="error-cuadrático-medio"><span class="header-section-number">4.1.1</span> Error cuadrático medio</h3>
<div class="definition">
<p>El <span class="green">error cuadrático medio (<em>mean squared error</em>, MSE) es la función de coste más utilizada en problemas de regresión</span>. Para una determinada observación <span class="math inline">\(i\)</span>, el error cuadrático se calcula como la diferencia al cuadrado entre el valor predicho <span class="math inline">\(\hat{y}\)</span> y el valor real <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[l_{sq}^{(i)}(w,b)=\left( \widehat{y}^{(i)}-y^{(i)}\right)^2\]</span></p>
</div>
</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>Las funciones de coste <span class="orange">suelen escribirse con la notación <span class="math inline">\(l(w,b)\)</span></span> para hacer referencia a que su valor depende de los pesos y el sesgo del modelo, ya que son estos los que determinan el valor de las predicciones <span class="math inline">\(\widehat{y}^{(i)}\)</span>.</p></li>
<li class="fragment"><p>Con frecuencia, esta función de coste <span class="orange">se encuentra multiplicada por <span class="math inline">\(\dfrac{1}{2}\)</span></span>, esto es simplemente por conveniencia matemática para simplificar el cálculo de su derivada.</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[L_{sq}^{(i)}(w,b)=\dfrac{1}{2}\left( \widehat{y}^{(i)}-y^{(i)}\right)^2\]</span></p>
</div>
</section>
<section class="slide level2">

<p>Para <span class="orange">cuantificar el error que comete el modelo en todo un conjunto de datos</span>, por ejemplo los de entrenamiento, se promedia el error de todas las <span class="math inline">\(N\)</span> observaciones.</p>
<div class="fragment">
<p><span class="math display">\[L_{sq}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}l^{(i)}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}\left( \widehat{y}^{(i)}-y^{(i)}\right)^{2}\]</span></p>
</div>
<div class="fragment">
<div class="alert">
<p>Cuando un modelo se <span class="orange">entrena utilizando el error cuadrático medio como función de coste, está aprendiendo a <strong>predecir la media de la variable respuesta</strong></span>.</p>
</div>
</div>
</section>
<section class="slide level2">

<h3 data-number="4.1.2" id="error-medio-absoluto"><span class="header-section-number">4.1.2</span> Error medio absoluto</h3>
<div class="definition">
<p>El <span class="green">error medio absoluto (<em>mean absolute error</em>, MAE)</span> consiste en <span class="orange">promediar el error absoluto de las predicciones</span>.</p>
<p><span class="math display">\[L(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}|\widehat{y}^{(i)}-y^{(i)}|\]</span></p>
</div>
</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>El error medio absoluto es <span class="orange">más robusto frente a <em>outliers</em></span> que el error cuadrático medio.</p></li>
<li class="fragment"><p>Esto significa que, el <span class="orange">entrenamiento del modelo, se ve menos influenciado por datos anómalos</span> que pueda haber en el conjunto de entrenamiento.</p></li>
<li class="fragment"><p>Cuando un modelo se entrena utilizando el error absoluto medio como función de coste, <span class="orange">está aprendiendo a <strong>predecir la mediana de la variable respuesta</strong></span>.</p></li>
</ul>
</section>
<section id="funciones-de-coste-para-clasificación" class="slide level2" data-number="4.2">
<h2><span class="header-section-number">4.2</span> Funciones de coste para clasificación</h2>
<div class="alert">
<div class="small">
<p>Las funciones de coste más comunes para problemas de clasificación:</p>
<ul>
<li class="fragment">Entropia cruzada binaria (Binary crossentropy):</li>
</ul>
<p><span class="math display">\[L_{bc}(M) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y^{(i)} \cdot log(\hat{y}^{(i)}) + (1 - y^{(i)}) \cdot log(1 - \hat{y}^{(i)}) \right]\]</span></p>
<ul>
<li class="fragment">Entropía cruzada categórica (Categorical crossentropy):</li>
</ul>
<p><span class="math display">\[L_{bc}(M) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} \left[ y^{(i,j)} \cdot log(\hat{y}^{(i,j)}) \right], \]</span></p>
<p>donde <span class="math inline">\(y^{(i,j)} =1\)</span>, si la clase de <span class="math inline">\(y^{(i,j)}\)</span> es <span class="math inline">\(j\)</span> y 0 en cualquier otro caso, <span class="math inline">\(\hat{y}^{(i,j)}\)</span> es la probabilidad entregada por el modelo para que la <span class="math inline">\(i\)</span>-ésima observación pertenezca a la <span class="math inline">\(j\)</span>-ésima clase.</p>
</div>
</div>
</section></section>
<section>
<section id="múltiples-capas" class="title-slide slide level1 center" data-background-color="#00A499" data-number="5">
<h1><span class="header-section-number">5</span> Múltiples capas</h1>

</section>
<section class="slide level2">

<div class="definition">
<ul>
<li class="fragment"><p>El modelo de red neuronal con <span class="green">una única capa (<strong>single-layer perceptron</strong>)</span>, aunque supuso un gran avance en el campo del <em>machine learning</em>, sólo <span class="orange">es capaz de aprender patrones sencillos</span>.</p></li>
<li class="fragment"><p>Para superar esta limitación, los investigadores descubrieron que, combinando <span class="green">múltiples capas ocultas</span>, la red puede aprender relaciones mucho más <span class="orange">complejas entre los predictores y la variable de respuesta</span>.</p></li>
<li class="fragment"><p>A esta estructura se le conoce como <span class="green"><strong>perceptrón multicapa</strong> o <strong>multilayer perceptron</strong> (MLP)</span>, y puede considerarse como el primer modelo de <strong>deep learning</strong>.</p></li>
</ul>
</div>
</section>
<section class="slide level2">

<ul>
<li class="fragment"><p>La estructura de <span class="green">un perceptrón multicapa consta de varias capas ocultas</span>. Cada neurona está conectada a todas las neuronas de la capa anterior y a las de la capa posterior.</p></li>
<li class="fragment"><p>Aunque no es estrictamente necesario, todas las neuronas que forman parte de <span class="orange">una misma capa suelen emplear la misma función de activación</span>.</p></li>
<li class="fragment"><p>Combinando <span class="orange">múltiples capas ocultas</span> y <span class="orange"><strong>funciones de activación no lineales</strong></span>, los modelos de redes pueden aprender prácticamente cualquier patrón. De hecho, está demostrado que, con <span class="green">suficientes neuronas, un MLP es un aproximador universal</span> para cualquier función.</p></li>
</ul>
<div class="example">
<p><span class="green">Tarea</span> Busque información sobre el <span class="blue">Teorema de aproximación universal</span></p>
</div>
</section>
<section class="slide level2">


<img data-src="images/02_DNN/DL_infinite_layers.png" class="r-stretch quarto-figure-center"><p class="caption">perceptrón multicapa</p></section></section>
<section>
<section id="entrenamiento" class="title-slide slide level1 center" data-background-color="#00A499" data-number="6">
<h1><span class="header-section-number">6</span> Entrenamiento</h1>

</section>
<section class="slide level2">

<div class="definition">
<p>El <span class="green">proceso de entrenamiento</span> de una red neuronal consiste en <span class="orange">ajustar el valor de los pesos y sesgo de tal forma que, las predicciones que se generen, tengan el menor error posible</span>. Gracias a esto, el modelo es capaz de identificar qué predictores tienen mayor influencia y de qué forma están relacionados entre ellos y con la variable de respuesta.</p>
</div>
</section>
<section class="slide level2">

<div class="alert">
<p>La idea intuitiva de cómo entrenar una red neuronal es la siguiente:</p>
<div class="small">
<ol type="1">
<li class="fragment"><p>Iniciar la red con valores aleatorios de los pesos y sesgo.</p></li>
<li class="fragment"><p>Para cada observación de entrenamiento, calcular el error que comete la red al hacer su predicción. Promediar los errores de todas las observaciones.</p></li>
<li class="fragment"><p>Identificar la responsabilidad que ha tenido cada peso y sesgo en el error de las predicciones.</p></li>
<li class="fragment"><p>Modificar ligeramente los pesos y sesgos de la red (de forma proporcional a su responsabilidad en el error) en la dirección correcta para que se reduzca el error.</p></li>
<li class="fragment"><p>Repetir los pasos 2, 3, 4 y 5 hasta que la red sea suficientemente buena.</p></li>
</ol>
</div>
</div>
<p><br></p>
<p>Si bien, la idea parece sencilla, el alcanzar una forma de implementarla ha requerido la combinación de múltiples métodos matemáticos, en particular, <span class="green"><em>backward</em> y <em>forward propagation</em></span></p>
</section>
<section class="slide level2">

<div class="alert">
<div>
<ul>
<li><p>En el proceso de entrenamiento, se <span class="orange">busca el mejor conjunto de parámetros</span> para <span class="orange">minimizar alguna de las funciones de coste</span> o pérdida.</p></li>
<li><p>La verdadera forma de la función de pérdida sólo puede ser construída si se tuviesen datos infinitos. Al ser finita la cantidad de datos que se tiene, la <span class="orange">función de pérdida obtenida no reflejará la verdadera forma de la función de pérdida</span>.</p></li>
</ul>
</div>
</div>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/02_DNN/training.png" style="width:80.0%"></p>
<figcaption>Minimización de una función de pérdida para un proceso de entrenamiento de 500 épocas</figcaption>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/02_DNN/training_hyperplane.png"></p>
<figcaption>Hiperplano que representa la función de pérdida con 2 parámetros.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section class="slide level2">


<img data-src="images/02_DNN/training_epochs.png" class="r-stretch quarto-figure-center"><p class="caption">Resultados de predicción de un modelo a través de las épocas</p></section>
<section id="backpropagation" class="slide level2" data-number="6.1">
<h2><span class="header-section-number">6.1</span> Backpropagation</h2>
<p><em>Backpropagation</em> es el algoritmo que permite cuantificar la influencia que tiene cada peso y bias en las predicciones de la red. Para conseguirlo, hace uso de la <strong>regla de la cadena</strong> para calcular el gradiente, que no es más que el vector formado por las derivadas parciales de una función.</p>
<p>En el caso de las redes, la derivada parcial del error respecto a un parámetro (peso o sesgo) mide cuánta <em>responsabilidad</em> ha tenido ese parámetro en el error cometido. Gracias a esto, se puede identificar qué pesos de la red hay que modificar para mejorarla. El siguiente paso necesario, es determinar cuánto y cómo modificarlos (optimización).</p>
</section>
<section class="slide level2">

<h3 data-number="6.1.1" id="prepocesamiento-de-variables"><span class="header-section-number">6.1.1</span> Prepocesamiento de variables</h3>
<p>A la hora de entrenar modelos basados en redes neuronales, es necesario aplicar a los datos, al menos, dos tipos de transformaciones.</p>
<ul>
<li class="fragment"><p><strong>Binarización (one hot encoding) de las variables categóricas</strong>: La binarización consiste en crear nuevas variables <em>dummy</em> con cada uno de los niveles de las variables cualitativas. Este proceso es el mismo realizado en modelos lineales.</p></li>
<li class="fragment"><p><strong>Estandarización y escalado de variables numéricas</strong>: Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Para ello, en general centramos los datos, y estandarizamos o reescalamos entre 0 y 1.</p></li>
</ul>
</section></section>
<section>
<section id="hiperparámetros" class="title-slide slide level1 center" data-background-color="#00A499" data-number="7">
<h1><span class="header-section-number">7</span> Hiperparámetros</h1>

</section>
<section class="slide level2">

<p>La gran “flexibilidad” que tienen las redes neuronales es un arma de doble filo. Por un lado, son capaces de generar modelos que aprenden relaciones muy complejas, sin embargo, sufren fácilmente el problema de sobreajuste (<em>overfitting</em>) lo que los <strong>incapacita al tratar de predecir nuevas observaciones</strong>.</p>
<p>La forma de minimizar este problema y conseguir modelos útiles pasa por configurar de forma adecuada sus hiperparámetros. Son muchos los hiperparámetros de un modelo basado en redes y su nomenclatura varía de unas implementaciones a otras, sin embargo, los de mayor impacto siempre están presentes:</p>
<ul>
<li class="fragment"><p>Número y tamaño de capas</p></li>
<li class="fragment"><p><em>Learning rate</em></p></li>
<li class="fragment"><p>Algoritmo de optimización</p></li>
<li class="fragment"><p>Regularización</p></li>
</ul>
</section>
<section id="número-y-tamaño-de-capas" class="slide level2" data-number="7.1">
<h2><span class="header-section-number">7.1</span> Número y tamaño de capas</h2>
<p>La arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.</p>
<p>La capa de entrada y salida son sencillas de establecer. La capa de entrada tiene tantas neuronas como predictores y la capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento. El usuario suele especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas.</p>
<p>Cuantas más neuronas y capas, mayor la complejidad de las relaciones que puede aprender el modelo. Sin embargo, dado que cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento.</p>
</section>
<section id="learning-rate" class="slide level2" data-number="7.2">
<h2><span class="header-section-number">7.2</span> Learning rate</h2>
<p>El <em>learning rate</em> o tasa de aprendizaje establece cuan rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interacciona con el resto de hiperparámetros. Si el <em>learning rate</em> es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse. Algunas de las recomendaciones <strong>heurísticas</strong> basadas en prueba y error son:</p>
<ul>
<li class="fragment"><p>Utilizar un <em>learning rate</em> lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.</p></li>
<li class="fragment"><p>No utilizar un valor constante de <em>learning rate</em> durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final.</p></li>
</ul>
</section>
<section id="algoritmo-de-optimización" class="slide level2" data-number="7.3">
<h2><span class="header-section-number">7.3</span> Algoritmo de optimización</h2>
<p>El descenso de gradiente y el descenso de gradiente estocástico fueron de los primeros métodos de optimización utilizados para entrenar modelos de redes neuronales. Ambos utilizan directamente el gradiente para dirigir la optimización. Pronto se vio que esto genera problemas a medida que las redes aumentan de tamaño (neuronas y capas). En muchas regiones del espacio de búsqueda, el gradiente es muy próximo a cero, lo que hace que la optimización quede estancada. Para evitar este problema, se han desarrollado modificaciones del descenso de gradiente capaces de adaptar el <em>learning rate</em> en función del gradiente y subgradiente. De esta forma, el proceso de aprendizaje se ralentiza o acelera dependiendo de las características de la región del espacio de búsqueda en el que se encuentren. Aunque existen multitud de adaptaciones, suele recomendarse:</p>
<ul>
<li class="fragment"><p>Para conjuntos de datos pequeños: <strong>l-bfgs</strong> (<em>limited memory bfgs</em>)</p></li>
<li class="fragment"><p>Para conjuntos de datos grandes: <strong>adam o rmsprop</strong> (<em>root mean square propagation</em>)</p></li>
</ul>
<p>La elección del algoritmo de optimización puede tener un impacto notable en el aprendizaje de los modelos, sobre todo en <em>deep learning</em>.</p>
</section>
<section id="regularización" class="slide level2" data-number="7.4">
<h2><span class="header-section-number">7.4</span> Regularización</h2>
<p>Los métodos de regularización tienen el objetivo de reducir el sobreajuste (<em>overfitting</em>) de los modelos. Un modelo con sobreajuste memoriza los datos de entrenamiento pero es incapaz de predecir correctamente nuevas observaciones.</p>
<p>Los modelos de redes neuronales pueden considerarse como <strong>modelos sobre parametrizados</strong>, por lo tanto, las estrategias de regularización son fundamentales. De entre las muchas que existen, destacan la regularización <strong>L1</strong> y <strong>L2</strong> (<em>weight decay</em>) y el <em>dropout</em>.</p>
</section></section>
<section id="referencias" class="title-slide slide level1 smaller scrollable" data-number="8">
<h1><span class="header-section-number">8</span> Referencias</h1>
<div id="refs" role="list">

</div>
<div class="quarto-auto-generated-content">
<p><img src="images/Usach_P2.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Deep_Learning_02_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Deep_Learning_02_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Deep_Learning_02_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'multiplex': {"secret":null,"id":"2b17915f5b5a749b","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    

    <script>

      // htmlwidgets need to know to resize themselves when slides are shown/hidden.

      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current

      // slide changes (different for each slide format).

      (function () {

        // dispatch for htmlwidgets

        function fireSlideEnter() {

          const event = window.document.createEvent("Event");

          event.initEvent("slideenter", true, true);

          window.document.dispatchEvent(event);

        }

    

        function fireSlideChanged(previousSlide, currentSlide) {

          fireSlideEnter();

    

          // dispatch for shiny

          if (window.jQuery) {

            if (previousSlide) {

              window.jQuery(previousSlide).trigger("hidden");

            }

            if (currentSlide) {

              window.jQuery(currentSlide).trigger("shown");

            }

          }

        }

    

        // hookup for slidy

        if (window.w3c_slidy) {

          window.w3c_slidy.add_observer(function (slide_num) {

            // slide_num starts at position 1

            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);

          });

        }

    

      })();

    </script>

    

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copiado");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copiado");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>