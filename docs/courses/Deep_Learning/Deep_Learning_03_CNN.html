<!DOCTYPE html>
<html lang="es"><head>
<script src="Deep_Learning_03_CNN_files/libs/clipboard/clipboard.min.js"></script>
<script src="Deep_Learning_03_CNN_files/libs/quarto-html/tabby.min.js"></script>
<script src="Deep_Learning_03_CNN_files/libs/quarto-html/popper.min.js"></script>
<script src="Deep_Learning_03_CNN_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Deep_Learning_03_CNN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Deep_Learning_03_CNN_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Deep_Learning_03_CNN_files/libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="Deep_Learning_03_CNN_files/libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">
<meta name="author" content="Francisco Plaza Vega">
<title>Deep Learning</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="Deep_Learning_03_CNN_files/libs/revealjs/dist/reset.css">
<link rel="stylesheet" href="Deep_Learning_03_CNN_files/libs/revealjs/dist/reveal.css">
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
<link rel="stylesheet" href="Deep_Learning_03_CNN_files/libs/revealjs/dist/theme/quarto.css">
<link href="Deep_Learning_03_CNN_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
<link href="Deep_Learning_03_CNN_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
<style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
<style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center"><h1 class="title">Deep Learning</h1>
  <p class="subtitle">Unidad 3: Redes Neuronales Convolucionales (CNN)</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Francisco Plaza Vega 
</div>
<div class="quarto-title-author-email">
<a href="mailto:francisco.plaza.v@usach.cl">francisco.plaza.v@usach.cl</a>
</div>
        <p class="quarto-title-affiliation">
            Ingeniería en Estadística
          </p>
    </div>
</div>

</section><section><section id="redes-neuronales-convolucionales" class="title-slide slide level1 center" data-background-color="#00A499" data-number="1"><h1>
<span class="header-section-number">1</span> Redes Neuronales Convolucionales</h1>

</section><section id="los-bloques-con-los-que-se-construyen-las-cnns" class="slide level2" data-number="1.1"><h2>
<span class="header-section-number">1.1</span> Los bloques con los que se construyen las CNNs</h2>
<p>Las CNNs son una familia de modelos que fueron originalmente inspirados por cómo funciona el cerebro humano al reconocer objetos.</p>

<img data-src="images/03_CNN/human_vision.png" class="r-stretch quarto-figure-center"><p class="caption">Esquema del sistema óptico humano</p></section><section class="slide level2"><h3 data-number="1.1.1" id="la-corteza-visual-humana">
<span class="header-section-number">1.1.1</span> La corteza visual humana</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment"><p>El descubrimiento original de cómo la corteza visual de nuestro cerebro funciona fue hecho por <span class="citation" data-cites="Hubel1959">Hubel y Wiesel (<a href="#/referencias" role="doc-biblioref" onclick="">1959</a>)</span>, a través de la inserción de un microelectrodo en la corteza visual de un gato anestesiado.</p></li>
<li class="fragment"><p>Observaron que las neuronas cerebrales responden de forma diferente después de proyectar diferentes patrones de luz en frente del gato.</p></li>
<li class="fragment"><p>Esto eventualmente llevó al descubrimiento de las diferentes capas de la corteza visual.</p></li>
<li class="fragment"><p>Mientras que la capa primaria detecta principalmente bordes y líneas rectas, las capas superiores se enfocan más en extraer patrones y formas complejas.</p></li>
</ul>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/03_CNN/hubel_wiesel_experiment.png"></p>
<figcaption>Imagen extraída de <span class="citation" data-cites="Li2022">Li, Todo, y Tang (<a href="#/referencias" role="doc-biblioref" onclick="">2022</a>)</span></figcaption></figure>
</div>
</div>
</div>
</section><section class="slide level2"><h3 data-number="1.1.2" id="algo-de-historia">
<span class="header-section-number">1.1.2</span> Algo de historia</h3>
<div class="definition">
<ul>
<li class="fragment"><p>El desarrollo de las CNNs se remonta a los años 90, cuando Yann LeCun y sus colegas propusieron una nueva arquitectura de red neuronal para clasificar dígitos escritos a mano desde imágenes <em><a href="https://proceedings.neurips.cc/paper_files/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf">Handwritten Digit Recognition with a Back-Propagation Network</a></em> <span class="citation" data-cites="LeCun1989">(<a href="#/referencias" role="doc-biblioref" onclick="">LeCun et&nbsp;al. 1989</a>)</span>, publicado en la conferencia de Sistemas de Procesamiento de Información Neural (<em>NeurIPS</em>).</p></li>
<li class="fragment"><p>Debido al rendimiento sobresaliente de las CNNs para tareas de clasificación de imágenes, este tipo particular de red neuronal feedforward ganó mucha atención y condujo a mejoras tremendas en los sistemas de aprendizaje de máquinas en evolución.</p></li>
<li class="fragment"><p>Varios años más tarde, en 2019, Yann LeCun recibió el premio Turing (el premio más prestigioso en la ciencia de computadoras) por sus contribuciones al campo de la inteligencia artificial (IA), junto con otros investigadores, Yoshua Bengio y Geoffrey Hinton.</p></li>
</ul>
</div>
<div class="quarto-figure quarto-figure-center">
<figure><div class="quarto-figure quarto-figure-center">
<figure><p><a href="images/03_CNN/turing_award.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1" title="Premiación de LeCun, Hinton y Bengio (de izquierda a derecha)"><img data-src="images/03_CNN/turing_award.png" class="quarto-figure quarto-figure-center" style="width:30.0%" alt="Premiación de LeCun, Hinton y Bengio (de izquierda a derecha)"></a></p>
</figure>
</div>
<figcaption>Premiación de LeCun, Hinton y Bengio (de izquierda a derecha)</figcaption></figure>
</div>
</section><section class="slide level2"><div class="definition">
<p>Las <span class="green"><strong>Convolutional Neural Networks</strong> o <strong>CNNs</strong></span>, son un tipo especial de redes neuronales para procesar datos que tienen una topología en forma de cuadrícula conocida. Como por ejemplo, series de tiempo, que pueden ser pensados como una malla 1-dimensional que toman datos a intervalos regulares, datos de imagen, que pueden ser pensados como una malla 2-dimensional.</p>
<ul>
<li class="fragment"><p>Este tipo de redes neuronales ha sido <span class="green"><strong>muy</strong></span> exitoso en la industria y práctica.</p></li>
<li class="fragment"><p>El nombre <strong>red neuronal convolucional</strong> indica que la red utiliza una operación matemática especifica: la <span class="green"><strong>convolución</strong></span>, esta es un tipo especial de operación lineal.</p></li>
<li class="fragment"><p><span class="orange"><em>Las redes neuronales convolucionales son simplemente redes neuronales que usan convolución en lugar de una multiplicación matricial en al menos una de sus capas</em></span></p></li>
</ul>
</div>
</section></section><section><section id="cnns-y-las-jerarquías-de-características" class="title-slide slide level1 center" data-background-color="#00A499" data-number="2"><h1>
<span class="header-section-number">2</span> CNNs y las jerarquías de características</h1>

</section><section class="slide level2"><ul>
<li class="fragment"><p><span class="green">La exitosa extracción de características relevantes</span> es clave para el rendimiento de cualquier algoritmo de aprendizaje automático y los modelos de aprendizaje automático tradicionales dependen de las características que pueden venir de un experto en el dominio o que se basan en técnicas computacionales de extracción de características.</p></li>
<li class="fragment">
<p>Las CNNs son capaces de <span class="green">aprender automáticamente las características de los datos en bruto</span> que son más útiles para una tarea específica. Por esta razón, es común considerar <span class="orange">las capas de las CNNs como extractores de características</span>:</p>
<ul>
<li class="fragment"><p>las capas iniciales (justo después de la capa de entrada) extraen características de bajo nivel de los datos en bruto,</p></li>
<li class="fragment"><p>y las capas posteriores, a menudo completamente conectadas (<em>fully connected</em>) como en un perceptrón multicapa (MLP) utilizan estas características para predecir un valor objetivo continuo o una etiqueta de clase.</p></li>
</ul>
</li>
<li class="fragment"><p>Ciertos tipos de NNs multicapas, y en particular, las redes neuronales convolucionales profundas (deep CNNs), construyen lo que se llama una <span class="green">jerarquía de características</span> combinando las características de bajo nivel en una secuencia de capas para formar características de alto nivel.</p></li>
</ul></section><section class="slide level2"><ul>
<li class="fragment"><p>Si se quiere preservar la información espacial de una imagen u otra forma de datos, entonces es conveniente representar cada imagen con una matriz de píxeles.</p></li>
<li class="fragment"><p>Una forma simple de codificar la estructura local es conectar una submatriz de neuronas de entrada adyacentes en una única neurona oculta que pertenece a la siguiente capa. Esa única neurona oculta representa un <span class="orange">campo receptivo local</span>.</p></li>
<li class="fragment"><p>Esta operación se denomina <span class="orange">convolución</span>, y es de donde se deriva el nombre para este tipo de red.</p></li>
<li class="fragment"><p>Una forma intuitiva de pensar en la convolución es como el tratamiento de una matriz por otra matriz, a la que <span class="orange">se le llama kernel</span>.</p></li>
</ul></section><section class="slide level2"><div class="example">
<p><span class="green">Ejemplo</span> </p>
<p>Por ejemplo, si estamos tratando con imágenes, entonces las características de bajo nivel, como bordes y manchas, se extraen de las capas anteriores, las cuales se combinan para formar características de alto nivel. Estas características de alto nivel pueden formar formas más complejas, como los contornos generales de objetos como edificios, gatos o perros.</p>
</div>
<p>Una CNN calcula mapas de características de una imagen de entrada, donde cada elemento proviene de un parche local de píxeles en la imagen de entrada:</p>

<img data-src="images/03_CNN/dog_features.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2"><div class="columns">
<div class="column" style="width:30%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="Deep_Learning_03_CNN_files/figure-revealjs/unnamed-chunk-2-1.png" class="quarto-figure quarto-figure-center" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:70%;">
<ul>
<li class="fragment">
<p>Supongamos que el tamaño de cada submatriz es de <span class="math inline">\(5 \times 5\)</span> y que esas submatrices se utilizan con imágenes MNIST de <span class="math inline">\(28 \times  28\)</span> píxeles. Entonces seremos capaces de generar <span class="math inline">\(24 \times 24\)</span> neuronas de campo receptivo local en la capa oculta. De hecho, es posible deslizar las submatrices solo 23 posiciones antes de tocar los bordes de las imágenes.</p>
<ul>
<li class="fragment"><p>En <code>TensorFlow</code>, el <span class="orange">número de píxeles a lo largo de un borde del kernel o submatriz, es el tamaño del kernel</span>,</p></li>
<li class="fragment"><p>y la <span class="orange">longitud del paso es el número de píxeles por los cuales el kernel se mueve en cada paso de la convolución</span>.</p></li>
</ul>
</li>
<li class="fragment"><p>Definamos el mapa de características de una capa a otra. Por supuesto, podemos tener múltiples mapas de características que aprenden independientemente de cada capa oculta. Por ejemplo, podemos empezar con <span class="math inline">\(28 \times 28\)</span> neuronas de entrada para procesar imágenes <code>MNIST</code>, y luego definir <span class="math inline">\(k\)</span> mapas de características de tamaño <span class="math inline">\(24 \times 24\)</span> neuronas cada uno (nuevamente con forma de <span class="math inline">\(5 \times 5\)</span>) en la siguiente capa oculta.</p></li>
</ul>
</div>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>Típicamente, las <span class="green">CNNs están compuestas por varias capas convolucionales y de submuestreo (<em>pooling</em>)</span> que son seguidas por una o más capas <span class="orange"><em>fully connected</em></span> al final. Las capas <em>fully connected</em> son esencialmente un MLP, donde cada unidad de entrada, <span class="math inline">\(i\)</span>, está conectada a cada unidad de salida, <span class="math inline">\(j\)</span>, con un peso <span class="math inline">\(w_{ij}\)</span>.</p></li>
<li class="fragment"><p>Las capas de submuestreo (<em>pooling</em>), comúnmente conocidas como capas de agrupamiento (pooling layers), no tienen parámetros que se puedan aprender; por ejemplo, no hay unidades de peso o sesgo en las capas de <em>pooling</em>. Sin embargo, tanto las capas convolucionales como las <em>fully connected</em> tienen pesos y sesgos que son optimizados durante el entrenamiento.</p></li>
</ul>

<img data-src="images/03_CNN/CNN_scheme.png" class="r-stretch quarto-figure-center"><p class="caption">Esquema de una CNN</p></section><section id="convolución" class="slide level2" data-number="2.1"><h2>
<span class="header-section-number">2.1</span> Convolución</h2>
<div class="definition">
<p>En su forma general, la convolución es una operación sobre dos funciones con argumentos reales.</p>
</div>
<p></p>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/03_CNN/laser.jpg" class="quarto-figure quarto-figure-center" style="width:70.0%"></p>
</figure>
</div>
</div><div class="column" style="width:60%;">
<ul>
<li class="fragment"><p><span class="green"><em>Supongamos que estamos rastreando la ubicación de una nave espacial con un sensor láser</em></span>. Nuestro sensor láser <span class="orange">nos entrega una sola salida <span class="math inline">\(x(t)\)</span>, la posición de la nave espacial en el tiempo <span class="math inline">\(t\)</span></span>, en donde <span class="math inline">\(x\)</span> y <span class="math inline">\(t\)</span> son valores reales.</p></li>
<li class="fragment"><p><span class="green">Ahora supongamos que nuestro sensor laser es <em>algo ruidoso</em></span>. Para obtener una estimación menos ruidosa de la posición de la nave, <span class="orange">podriamos promediar muchas mediciones, siendo las mediciones más recientes más relevantes</span>, por lo que sería un promedio ponderado que otorga más peso a las observaciones más recientes.</p></li>
</ul>
</div>
</div>
</section><section class="slide level2"><p>Podemos hacer esto con una función <span class="math inline">\(w(a)\)</span>, donde <span class="math inline">\(a\)</span> es la <em>edad</em> de la medición. Si deseamos aplicar la operación de ponderación en cada momento, debemos obtener una nueva función <span class="math inline">\(s\)</span> que entregue una estimación suavizada de la posición de la nave:</p>
<p><span class="math display">\[s(t)=\int x(a)w(t-a)da\]</span> Esta operación es llamada <span class="green"><strong>convolución</strong></span>. La operaciónde convolución se denota típicamente como:</p>
<p><span class="math display">\[s(t)=(x * w)(t)\]</span></p>
</section><section class="slide level2"><p>En nuestro caso, <span class="math inline">\(w\)</span> necesita ser una función de densidad de probabilidad válida, sino la salida no sería una ponderación. Además, <span class="math inline">\(w\)</span> necesita ser 0 para todos los argumentos negativos, o esta función mirará en el futuro. Estas limitaciones son particulares de nuestro ejemplo. En general, la convolución está definida para cualquier función para que la integral anterior está definida, y puede ser ocupada con otros fines.</p>
<p>En este contexto, el <span class="green">primer argumento (<span class="math inline">\(x\)</span>) se le llama <strong>input</strong></span> y el <span class="green">segundo argumento (<span class="math inline">\(w\)</span>) se le llama <strong>kernel</strong></span>, y a la <span class="green">salida se le llama <strong>feature map</strong></span></p>
<p>En nuestro ejemplo, la idea de que el sensor láser entregue medidas en cada instante de tiempo no es realista, pues trabajamos con una discretización del tiempo, usualmente a tiempos regulares. Así, tendremos:</p>
<p><span class="math display">\[s(t)=(x*w)(t)=\sum_{a=-\infty}^{\infty}x(a)w(t-a)\]</span></p>
</section><section class="slide level2"><p>Frecuentemente usamos convoluciones sobre más de un eje en un tiempo especifico. Por ejemplo, si usamos una imagen 2-dimensional <span class="math inline">\(I\)</span> como <strong>input</strong>, probablemente desearemos usar un kernel <span class="math inline">\(K\)</span> 2-dimensional:</p>
<p><span class="math display">\[S(i,j)=(I*K)(i,j)=\sum_m \sum_n I(m,n)K(i-m,j-n)\]</span></p>
<p>La convolución es <strong>conmutativa</strong>, esto significa que equivalentemente podemos escribir:</p>
<p><span class="math display">\[S(i,j)=(K*I)(i,j)=\sum_m \sum_n I(i-m,j-n)K(m,n)\]</span></p>
</section><section class="slide level2"><h3 data-number="2.1.1" id="motivación">
<span class="header-section-number">2.1.1</span> Motivación</h3>
<div class="alert">
<p>El parche local de elementos que participan de la convolución, se conoce como el <span class="green">campo receptivo local</span>. Las <span class="green">CNNs generalmente se desempeñan muy bien en tareas relacionadas con imágenes</span>, y eso se debe en gran medida a tres ideas importantes:</p>
<ul>
<li class="fragment"><p><span class="orange">Conectividad dispersa (<em>sparse connectivity</em>)</span>: Un único elemento en el mapa de características está conectado solo a un pequeño parche de píxeles. (Esto es muy diferente de conectar a toda la imagen de entrada como en el caso de los perceptrones.</p></li>
<li class="fragment"><p><span class="orange">Compartir parámetros (<em>parameter sharing</em>)</span>: Los mismos pesos se utilizan para diferentes parches de la imagen de entrada.</p></li>
<li class="fragment"><p><span class="orange">Representación equivariante (<em>equivariant representation</em>)</span>: Desplazar la señal de entrada resulta en una señal de salida igualmente desplazada. La mayoría de nosotros podemos reconocer rostros específicos bajo una variedad de condiciones porque aprendemos abstracción. Estas abstracciones son, por lo tanto, invariantes al tamaño, contraste, rotación y orientación.</p></li>
</ul>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>Como consecuencia directa de estas ideas, <span class="orange">reemplazar una red <em>fully connected</em> (MLP) convencional por una capa de convolución</span> reduce sustancialmente el número de pesos (parámetros) en la red y veremos una mejora en la capacidad de capturar características inherentes.</p></li>
<li class="fragment"><p>En el contexto de los datos de imagen, tiene sentido suponer que los píxeles cercanos son típicamente más relevantes entre sí que los píxeles que están lejos unos de otros.</p></li>
<li class="fragment"><p>Además de permitir trabajar con entradas de tamaño variable.</p></li>
</ul></section><section class="slide level2"><h4 id="sparse-connectivity">Sparse connectivity</h4>
<p>Interacciones escasas o sparse interactions (que también se le refiere como <strong>sparse connectivity</strong> o <strong>sparse weights</strong>), viene desde la siguiente idea:</p>
<blockquote>
<p>Las capas de una red neuronal tradicional usan multiplicación de matrices por una matriz de parámetros con un parámetro separado que describe la interacción entre cada unidad de entrada y cada unidad de salida.</p>
</blockquote>
<ul>
<li class="fragment"><p>Esto significa que <span class="orange">cada unidad de salida interactúa con cada unidad de entrada</span>. Las redes convolucionales, en cambio, no necesariamente. Este es <span class="orange">logrado utilizando <strong>kernels</strong> más pequeños que la entrada</span>.</p></li>
<li class="fragment"><p>Por ejemplo, cuando se procesa una imagen, la entrada podría tener millones de pixeles, pero es posible detectar unas pequeñas pero relevantes características, que al interactuar con el <em>kernel</em> ocupan sólo cientos de pixeles. Esto implica <span class="green">guardar mucho menos parámetros</span>, que reduce la memoria requerida del modelo y mejora su eficiencia estadística.</p></li>
</ul></section><section class="slide level2">
<img data-src="images/03_CNN/sparse.png" class="r-stretch quarto-figure-center"><p class="caption">Sparse connectivity</p></section><section class="slide level2"><h4 id="parameter-sharing-y-equivariance-representation">Parameter sharing y equivariance representation</h4>
<ul>
<li class="fragment"><p>Esta característica hace referencia a usar los mismos parámetros para más de una función en un modelo. Reduciendo así, el número de parámetros a optimizar y mejorando la eficiencia estadística.</p></li>
<li class="fragment"><p>Configurando particularmente los parámetros, podemos obtener la propiedad de representación de equivalencia, que refiere a que si las entradas cambian, las salidas cambian <strong>en la misma manera</strong>.</p></li>
</ul></section><section class="slide level2">
<img data-src="images/03_CNN/sharing.png" class="r-stretch quarto-figure-center"><p class="caption">Parameter sharing</p></section><section class="slide level2"><div class="alert">
<p><span class="blue">Importante</span></p>
<p>En las siguientes diapositivas, estudiaremos las capas convolucionales y de <em>pooling</em> con más detalle y veremos cómo funcionan. Para entender cómo funcionan las operaciones de convolución, empezaremos con una convolución en una dimensión, que a veces se utiliza para trabajar con ciertos tipos de datos secuenciales, como el texto. Después, trabajaremos a través de las convoluciones bidimensionales, que se aplican comúnmente a imágenes.</p>
</div>
</section><section class="slide level2"><h3 data-number="2.1.2" id="convoluciones-1-d">
<span class="header-section-number">2.1.2</span> Convoluciones 1-D</h3>
<div class="definition">
<p><span class="blue"><strong>Notación</strong></span></p>
<p>En esta parte, usaremos subíndices para denotar el tamaño de un arreglo multidimensional (tensor); por ejemplo, <span class="math inline">\(A_{n_1 \times n_2}\)</span> es un arreglo bidimensional de tamaño <span class="math inline">\(n_1 \times n_2\)</span>. Usamos corchetes, <span class="math inline">\(\left[ \; \right]\)</span>, para denotar la indexación de un arreglo multidimensional.</p>
<p>Por ejemplo, <span class="math inline">\(A[i, j]\)</span> se refiere al elemento en el índice i, j de la matriz A. Además, observe que usamos un símbolo especial, <span class="math inline">\(*\)</span>, para denotar la operación de convolución entre dos vectores o matrices, lo cual no debe confundirse con el operador de multiplicación, <code>*</code>, que típicamente utilizamos en <code>R</code> o <code>Python</code>.</p>
</div>
</section><section class="slide level2"><p>Una convolución discreta<sup>1</sup> para dos vectores, <span class="math inline">\(x\)</span> y <span class="math inline">\(w\)</span>, se denota por <span class="math inline">\(y = x * w\)</span>, donde el vector <span class="math inline">\(x\)</span> es nuestra entrada (a veces llamado señal) y <span class="math inline">\(w\)</span> se llama el filtro o kernel. Una convolución se define matemáticamente de la siguiente manera:</p>
<p><span class="math display">\[
y = x * w \rightarrow y[i] = \sum_{k=-\infty}^{+\infty} x[i - k] \cdot w[k]
\]</span></p>
<p>Como se mencionó anteriormente, los corchetes, [], se usan para denotar la indexación para los elementos del vector. El índice, <span class="math inline">\(i\)</span>, recorre cada elemento del vector de salida, <span class="math inline">\(y\)</span>.</p>
<aside><ol class="aside-footnotes"><li id="fn1"><p>O de aquí en adelante, sólo convolución</p></li></ol></aside></section><section class="slide level2"><div class="alert">
<p>Hay dos puntos a mencionar a partir de la fórmula anterior que deben ser destacados:</p>
<ul>
<li class="fragment"><p>índices de <span class="math inline">\(-\infty\)</span> a <span class="math inline">\(+\infty\)</span></p></li>
<li class="fragment"><p>indexación negativa para <span class="math inline">\(x\)</span>.</p></li>
</ul>
</div>
<ul>
<li class="fragment"><p>El hecho de que la suma recorra índices de <span class="math inline">\(-\infty\)</span> a <span class="math inline">\(+\infty\)</span> parece raro, principalmente porque en aplicaciones de CNN siempre tratamos con vectores de características finitas.</p></li>
<li class="fragment"><p>Por ejemplo, si <span class="math inline">\(x\)</span> tiene 10 características con índices <span class="math inline">\(0, 1, 2,\ldots, 9\)</span>, entonces los índices <span class="math inline">\(-\infty = -1\)</span> y <span class="math inline">\(10 : +\infty\)</span> estarían fuera de los límites para <span class="math inline">\(x\)</span>.</p></li>
<li class="fragment"><p>Por lo tanto, para calcular correctamente la sumatoria mostrada en la fórmula anterior, se asume que <span class="math inline">\(x\)</span> y <span class="math inline">\(w\)</span> están <span class="orange">rellenados con ceros</span>. Esto resultará en un vector de salida, <span class="math inline">\(y\)</span>, que también tiene un tamaño infinito, con muchos ceros también. Dado que esto no es útil en situaciones prácticas, a <span class="math inline">\(x\)</span> se le añaden solo un número finito de ceros.</p></li>
</ul></section><section class="slide level2"><p>Este proceso se llama relleno de ceros o simplemente relleno (<span class="green"><em>padding</em></span>). Aquí, el número de ceros añadidos a cada lado se denota por <span class="math inline">\(p\)</span>. Un ejemplo de relleno para un vector unidimensional, <span class="math inline">\(x\)</span>, se muestra a continuación:</p>

<img data-src="images/03_CNN/1d_conv.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"></section><section class="slide level2"><p>Supongamos que la entrada original, <span class="math inline">\(x\)</span>, y el filtro, <span class="math inline">\(w\)</span>, tienen <span class="math inline">\(n\)</span> y <span class="math inline">\(m\)</span> elementos, donde <span class="math inline">\(m \leq n\)</span>. Por lo tanto, el vector rellenado, <span class="math inline">\(x^{'p}\)</span>, tiene tamaño <span class="math inline">\(n + 2p\)</span>. La fórmula práctica para calcular la convolución cambiará a la siguiente:</p>
<p><span class="math display">\[
y = x * w \rightarrow y[i] = \sum_{k=0}^{m-1} x^p[i + m - k] \cdot w[k]
\]</span></p>
<p>Ahora que hemos resuelto el problema del índice infinito, el segundo problema es indexar <span class="math inline">\(x\)</span> con <span class="math inline">\(i + m - k\)</span>. El punto importante a notar aquí es que <span class="math inline">\(x\)</span> y <span class="math inline">\(w\)</span> están indexados en diferentes direcciones en esta sumatoria. Calcular la suma con un índice yendo en la dirección inversa es equivalente a calcular la suma con ambos índices en la dirección hacia adelante después de voltear uno de esos vectores, <span class="math inline">\(x\)</span> o <span class="math inline">\(w\)</span>, después de que son rellenados. Entonces, simplemente podemos calcular su producto punto. Supongamos que invertimos (rotamos) el filtro, <span class="math inline">\(w\)</span>, para obtener el filtro rotado, <span class="math inline">\(w^r\)</span>. Entonces, el producto punto, <span class="math inline">\(x[i : i + m] \cdot w^r\)</span>, se calcula para obtener un elemento, <span class="math inline">\(y[i]\)</span>, donde <span class="math inline">\(x[i : i + m]\)</span> es un segmento de <span class="math inline">\(x\)</span> con tamaño <span class="math inline">\(m\)</span>. Esta operación se repite como en un enfoque de ventana deslizante para obtener todos los elementos de salida. La siguiente figura proporciona un ejemplo con <span class="math inline">\(x = [3, 2, 1, 7, 1, 2, 5, 4]\)</span> y <span class="math inline">\(w = \left[ \frac{1}{2}, \frac{3}{4}, 1, \frac{1}{4}\right]\)</span>, de modo que los primeros tres elementos de salida se calculan:</p>
</section><section class="slide level2">
<img data-src="images/03_CNN/1d_conv_2.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2"><p>En el ejemplo anterior se pueden notar algunos detalles:</p>
<ul>
<li class="fragment"><p>El tamaño del <em>padding</em> es cero (<span class="math inline">\(p = 0\)</span>).</p></li>
<li class="fragment"><p>El filtro rotado, <span class="math inline">\(w^r\)</span>, se desplaza dos celdas cada vez que se desliza. Este desplazamiento es otro hiperparámetro de una convolución, <span class="green">el paso o <em>stride</em></span>, <span class="math inline">\(s\)</span>. En este ejemplo, el stride es dos, <span class="math inline">\(s = 2\)</span>.</p></li>
<li class="fragment"><p>El <span class="orange"><em>stride</em> debe ser un número positivo menor que el tamaño del vector de entrada</span>.</p></li>
</ul></section><section class="slide level2"><h3 data-number="2.1.3" id="padding">
<span class="header-section-number">2.1.3</span> Padding</h3>
<p>Hasta ahora, solo hemos utilizado el <em>zero-padding</em> en las convoluciones para calcular vectores de salida de tamaño finito. Técnicamente, el <em>padding</em> se puede aplicar con cualquier <span class="math inline">\(p \geq 0\)</span>. Dependiendo de la elección de <span class="math inline">\(p\)</span>, las celdas en los bordes pueden ser tratadas de manera diferente a las celdas situadas en el medio de <span class="math inline">\(x\)</span>.</p>
<div class="alert">
<p>Existen tres modos de <em>padding</em> que se utilizan comúnmente en la práctica: <span class="green">completo (<em>full</em>), mismo (<em>same</em>) y válido (<em>valid</em>)</span>:</p>
<ul>
<li class="fragment"><p>En modo <span class="orange"><em>full</em></span>, el parámetro de relleno, <span class="math inline">\(p\)</span>, se establece en <span class="math inline">\(p = m - 1\)</span>. El <em>full padding</em> aumenta las dimensiones de la salida; por lo tanto, <span class="green">rara vez se usa en arquitecturas de CNN</span>.</p></li>
<li class="fragment"><p>El <span class="orange"><em>same padding</em></span> generalmente se utiliza para asegurar que el vector de salida tenga el mismo tamaño que el vector de entrada, <span class="math inline">\(x\)</span>. En este caso, el parámetro de <em>padding</em>, <span class="math inline">\(p\)</span>, se calcula de acuerdo al tamaño del filtro, junto con el requisito de que el tamaño de entrada y salida sean los mismos.</p></li>
<li class="fragment"><p>Finalmente, calcular una convolución usando <span class="orange"><em>valid padding</em></span> se refiere al caso donde <span class="math inline">\(p = 0\)</span> (sin <em>padding</em>).</p></li>
</ul>
</div>
</section><section class="slide level2">
<img data-src="images/03_CNN/padding.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2"><h3 data-number="2.1.4" id="determinando-el-tamaño-de-la-salida-de-la-convolución">
<span class="header-section-number">2.1.4</span> Determinando el tamaño de la salida de la convolución</h3>
<p>El tamaño de salida de una convolución está determinado por el número total de veces que se puede desplazar el filtro, <span class="math inline">\(w\)</span>, a lo largo del vector de entrada. Supongamos que el vector de entrada es de tamaño <span class="math inline">\(n\)</span> y el filtro es de tamaño <span class="math inline">\(m\)</span>. Entonces, el tamaño de la salida resultante de <span class="math inline">\(y = x * w\)</span>, con <em>padding</em>, <span class="math inline">\(p\)</span>, y <em>stride</em>, <span class="math inline">\(s\)</span>, se determinaría de la siguiente manera:</p>
<p><span class="math display">\[o = \left\lfloor \frac{n + 2p - m}{s} \right\rfloor + 1\]</span></p>
<p>Aquí, <span class="math inline">\(\lfloor \cdot \rfloor\)</span> denota la operación de redondeo hacia abajo (<em>floor</em>). Esta operación devuelve el entero más grande que es igual o menor que la entrada, por ejemplo: <span class="math inline">\(\text{floor}(1.77) = \lfloor 1.77 \rfloor = 1 \]\)</span></p>
</section><section class="slide level2"><h4 id="implementación">Implementación</h4>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-1-1">R</a></li>
<li><a href="#tabset-1-2">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href=""></a>conv1d <span class="ot">&lt;-</span> <span class="cf">function</span>(x, w, <span class="at">p =</span> <span class="dv">0</span>, <span class="at">s =</span> <span class="dv">1</span>) {</span>
<span id="cb1-2"><a href=""></a>  <span class="co"># Invertir el kernel para la convolución</span></span>
<span id="cb1-3"><a href=""></a>  w_rot <span class="ot">&lt;-</span> <span class="fu">rev</span>(w)</span>
<span id="cb1-4"><a href=""></a>  <span class="co"># Preparar el vector de entrada con el relleno inicial</span></span>
<span id="cb1-5"><a href=""></a>  x_padded <span class="ot">&lt;-</span> x</span>
<span id="cb1-6"><a href=""></a>  <span class="cf">if</span> (p <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-7"><a href=""></a>    <span class="co"># Añadir ceros para el relleno antes y después del vector original</span></span>
<span id="cb1-8"><a href=""></a>    x_padded <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, p), x_padded, <span class="fu">rep</span>(<span class="dv">0</span>, p))</span>
<span id="cb1-9"><a href=""></a>  }</span>
<span id="cb1-10"><a href=""></a>  <span class="co"># Inicializar el vector de resultados</span></span>
<span id="cb1-11"><a href=""></a>  res <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb1-12"><a href=""></a>  <span class="co"># Aplicar la convolución con el paso (stride) especificado</span></span>
<span id="cb1-13"><a href=""></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="fu">length</span>(x_padded) <span class="sc">-</span> <span class="fu">length</span>(w_rot) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">by =</span> s)) {</span>
<span id="cb1-14"><a href=""></a>    res <span class="ot">&lt;-</span> <span class="fu">c</span>(res, <span class="fu">sum</span>(x_padded[i<span class="sc">:</span>(i <span class="sc">+</span> <span class="fu">length</span>(w_rot) <span class="sc">-</span> <span class="dv">1</span>)] <span class="sc">*</span> w_rot))</span>
<span id="cb1-15"><a href=""></a>  }</span>
<span id="cb1-16"><a href=""></a>  <span class="fu">return</span>(res)</span>
<span id="cb1-17"><a href=""></a>}</span>
<span id="cb1-18"><a href=""></a></span>
<span id="cb1-19"><a href=""></a><span class="co"># Prueba:</span></span>
<span id="cb1-20"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb1-21"><a href=""></a>w <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb1-22"><a href=""></a><span class="fu">cat</span>(<span class="st">"Implementación Conv1d: "</span>, <span class="fu">conv1d</span>(x, w, <span class="at">p =</span> <span class="dv">2</span>, <span class="at">s =</span> <span class="dv">1</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Implementación Conv1d:  5 14 16 26 24 34 19 22 </code></pre>
</div>
</div>
</div>
<div id="tabset-1-2">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href=""></a></span>
<span id="cb3-3"><a href=""></a><span class="kw">def</span> conv1d(x, w, p<span class="op">=</span><span class="dv">0</span>, s<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb3-4"><a href=""></a>    w_rot <span class="op">=</span> np.array(w[::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-5"><a href=""></a>    x_padded <span class="op">=</span> np.array(x)</span>
<span id="cb3-6"><a href=""></a>    <span class="cf">if</span> p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb3-7"><a href=""></a>        zero_pad <span class="op">=</span> np.zeros(shape<span class="op">=</span>p)</span>
<span id="cb3-8"><a href=""></a>        x_padded <span class="op">=</span> np.concatenate([zero_pad, x_padded, zero_pad])</span>
<span id="cb3-9"><a href=""></a>    res <span class="op">=</span> []</span>
<span id="cb3-10"><a href=""></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">int</span>(<span class="bu">len</span>(x)<span class="op">/</span>s),s):</span>
<span id="cb3-11"><a href=""></a>        res.append(np.<span class="bu">sum</span>(x_padded[i:i<span class="op">+</span>w_rot.shape[<span class="dv">0</span>]] <span class="op">*</span> w_rot))</span>
<span id="cb3-12"><a href=""></a>    <span class="cf">return</span> np.array(res)</span>
<span id="cb3-13"><a href=""></a></span>
<span id="cb3-14"><a href=""></a><span class="co">## Prueba:</span></span>
<span id="cb3-15"><a href=""></a>x <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">3</span>]</span>
<span id="cb3-16"><a href=""></a>w <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb3-17"><a href=""></a><span class="bu">print</span>(<span class="st">'Implementación de Conv1d: '</span>, </span>
<span id="cb3-18"><a href=""></a>      conv1d(x, w, p<span class="op">=</span><span class="dv">2</span>, s<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Implementación de Conv1d:  [ 5. 14. 16. 26. 24. 34. 19. 22.]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a><span class="bu">print</span>(<span class="st">'Resultados de Numpy:         '</span>, </span>
<span id="cb5-2"><a href=""></a>      np.convolve(x, w, mode<span class="op">=</span><span class="st">'same'</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Resultados de Numpy:          [ 5 14 16 26 24 34 19 22]</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section class="slide level2"><h3 data-number="2.1.5" id="convolución-2-d">
<span class="header-section-number">2.1.5</span> Convolución 2-D</h3>
<p>Los conceptos que hemos visto hasta ahora son fácilmente extensibles a 2D. Cuando tratamos con entradas en 2D, como una matriz, <span class="math inline">\(X_{n1 \times n2}\)</span>, y la matriz del filtro, <span class="math inline">\(W_{m1 \times m2}\)</span>, donde <span class="math inline">\(m1 \leq n1\)</span> y <span class="math inline">\(m2 \leq n2\)</span>, entonces la matriz <span class="math inline">\(Y = X * W\)</span> es el resultado de una convolución en 2D entre <span class="math inline">\(X\)</span> y <span class="math inline">\(W\)</span>. Esto se define matemáticamente de la siguiente manera:</p>
<p><span class="math display">\[
Y = X * W \rightarrow Y[i,j] = \sum_{k1=-\infty}^{+\infty} \sum_{k2=-\infty}^{+\infty} X[i - k1,j - k2] \cdot W[k1,k2]
\]</span></p>
</section><section class="slide level2"><p>Notar que, todas las técnicas mencionadas anteriormente, como el <em>padding</em>, rotar la matriz del filtro, y el uso de <em>strides</em>, también son aplicables a convoluciones en 2D, siempre y cuando se extiendan a ambas dimensiones de manera independiente. La figura siguiente demuestra la convolución en 2D de una matriz de entrada de tamaño <span class="math inline">\(6 \times 6\)</span>, utilizando un kernel de tamaño <span class="math inline">\(2 \times 2\)</span>. La matriz se rellena con ceros con <span class="math inline">\(p = 1\)</span>. Como resultado, la salida de la convolución en 2D tendrá un tamaño de <span class="math inline">\(4 \times 4\)</span>:</p>

<img data-src="images/03_CNN/conv_2d.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2">
<img data-src="images/03_CNN/conv2d_2.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2">
<img data-src="images/03_CNN/conv2d_3.png" class="quarto-figure quarto-figure-center r-stretch"></section><section class="slide level2"></section></section><section id="referencias" class="title-slide slide level1 smaller scrollable" data-number="3"><h1>
<span class="header-section-number">3</span> Referencias</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Hubel1959" class="csl-entry" role="listitem">
Hubel, David H, y Torsten N Wiesel. 1959. <span>«Receptive fields of single neurones in the cat’s striate cortex»</span>. <em>The Journal of physiology</em> 148 (3): 574.
</div>
<div id="ref-LeCun1989" class="csl-entry" role="listitem">
LeCun, Yann, Bernhard Boser, John Denker, Donnie Henderson, Richard Howard, Wayne Hubbard, y Lawrence Jackel. 1989. <span>«Handwritten digit recognition with a back-propagation network»</span>. <em>Advances in neural information processing systems</em> 2.
</div>
<div id="ref-Li2022" class="csl-entry" role="listitem">
Li, Bin, Yuki Todo, y Zheng Tang. 2022. <span>«Artificial Visual System for Orientation Detection Based on Hubel–Wiesel Model»</span>. <em>Brain Sciences</em> 12 (4): 470.
</div>
</div>
<div class="quarto-auto-generated-content">
<p><img src="images/Usach_P2.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Premiación de LeCun, Hinton y Bengio (de izquierda a derecha)</span>
</div>
</section>
</div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="Deep_Learning_03_CNN_files/libs/revealjs/dist/reveal.js"></script><!-- reveal.js plugins --><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/reveal-menu/menu.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/multiplex/socket.io.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/multiplex/multiplex.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/quarto-support/support.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/notes/notes.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/search/search.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/zoom/zoom.js"></script><script src="Deep_Learning_03_CNN_files/libs/revealjs/plugin/math/math.js"></script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'multiplex': {"secret":null,"id":"e75ed69e9e8fbdcd","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script><script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }
    
        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();
    
          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }
    
        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }
    
      })();
    </script><script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copiado");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copiado");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script><script>var lightboxQuarto = GLightbox({"openEffect":"zoom","selector":".lightbox","loop":false,"descPosition":"bottom","closeEffect":"zoom"});
    window.onload = () => {
      lightboxQuarto.on('slide_before_load', (data) => {
        const { slideIndex, slideNode, slideConfig, player, trigger } = data;
        const href = trigger.getAttribute('href');
        if (href !== null) {
          const imgEl = window.document.querySelector(`a[href="${href}"] img`);
          if (imgEl !== null) {
            const srcAttr = imgEl.getAttribute("src");
            if (srcAttr && srcAttr.startsWith("data:")) {
              slideConfig.href = srcAttr;
            }
          }
        } 
      });

      lightboxQuarto.on('slide_after_load', (data) => {
        const { slideIndex, slideNode, slideConfig, player, trigger } = data;
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(slideNode);
        }
      });

    };
              </script>


</body></html>