@misc{hammersley1955million,
  title={A Million Random Digits with 100,000 Normal Deviates},
  author={Hammersley, JM},
  year={1955},
  publisher={Wiley Online Library}
}

@misc{cryptoeprint:2007/419,
      author = {Leo Dorrendorf and Zvi Gutterman and Benny Pinkas},
      title = {Cryptanalysis of the Random Number Generator of the Windows Operating System},
      howpublished = {Cryptology ePrint Archive, Paper 2007/419},
      year = {2007},
      note = {\url{https://eprint.iacr.org/2007/419}},
      url = {https://eprint.iacr.org/2007/419}
}

@article{bhattacharjee2022search,
  title={A search for good pseudo-random number generators: Survey and empirical studies},
  author={Bhattacharjee, Kamalika and Das, Sukanta},
  journal={Computer Science Review},
  volume={45},
  pages={100471},
  year={2022},
  publisher={Elsevier}
}

@Book{Goodfellow2016,
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher = {MIT press},
  title     = {Deep learning},
  year      = {2016},
}

@Book{Raschka2019,
  author    = {Raschka, Sebastian and Mirjalili, Vahid},
  publisher = {Packt Publishing Ltd},
  title     = {Python machine learning: Machine learning and deep learning with Python, scikit-learn, and TensorFlow 2},
  year      = {2019},
}

@Book{Geron2022,
  author    = {G{\'e}ron, Aur{\'e}lien},
  publisher = {O'Reilly Media, Inc.},
  title     = {{Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow}},
  year      = {2022},
}

@Article{Lovelace2015,
  author  = {Lovelace, AA},
  journal = {Ada User Journal},
  title   = {1842 Notes to the Translation of the Sketch of the Analytical Engine},
  year    = {2015},
  number  = {3},
  pages   = {152},
  volume  = {36},
}

@Article{Aiello2016,
  author    = {Aiello, Luigia Carlucci},
  journal   = {Artificial Intelligence},
  title     = {The multifaceted impact of Ada Lovelace in the digital age},
  year      = {2016},
  pages     = {58--62},
  volume    = {235},
  publisher = {Elsevier},
}

@InCollection{Jaeger2023,
  author    = {Jaeger, Lars},
  booktitle = {Women of Genius in Science: Whose Frequently Overlooked Contributions Changed the World},
  publisher = {Springer},
  title     = {Ada Lovelace (1815--1852): Inventor of Computer Algorithms},
  year      = {2023},
  pages     = {71--82},
}

 
@Article{2023,
  author    = {Nature Editorial},
  journal   = {Nature Computational Science},
  title     = {Ada {Lovelace}, a role model for the ages},
  year      = {2023},
  issn      = {2662-8457},
  month     = oct,
  number    = {10},
  pages     = {807--807},
  volume    = {3},
  abstract  = {Ada Lovelace Day celebrates women in STEM careers, but also raises awareness of the challenges that women have faced in science, as well as the importance of female role models in STEM.},
  copyright = {2023 Springer Nature America, Inc.},
  doi       = {10.1038/s43588-023-00541-z},
  file      = {Full Text PDF:https\://www.nature.com/articles/s43588-023-00541-z.pdf:application/pdf},
  keywords  = {Computer science, Education},
  language  = {en},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/s43588-023-00541-z},
  urldate   = {2024-02-20},
}

 
@Article{Moor2001,
  author   = {Moor, James H.},
  journal  = {Minds and Machines},
  title    = {The {Status} and {Future} of the {Turing} {Test}},
  year     = {2001},
  issn     = {1572-8641},
  month    = feb,
  number   = {1},
  pages    = {77--93},
  volume   = {11},
  abstract = {The standard interpretation of the imitation game is defended over the rival gender interpretation though it is noted that Turing himself proposed several variations of his imitation game. The Turing test is then justified as an inductive test not as an operational definition as commonly suggested. Turing's famous prediction about his test being passed at the 70\% level is disconfirmed by the results of the Loebner 2000 contest and the absence of any serious Turing test competitors from AI on the horizon. But, reports of the death of the Turing test and AI are premature. AI continues to flourish and the test continues to play an important philosophical role in AI. Intelligence attribution, methodological, and visionary arguments are given in defense of a continuing role for the Turing test. With regard to Turing's predictions one is disconfirmed, one is confirmed, but another is still outstanding.},
  doi      = {10.1023/A:1011218925467},
  file     = {Full Text PDF:https\://link.springer.com/content/pdf/10.1023%2FA%3A1011218925467.pdf:application/pdf},
  keywords = {imitation game, Loebner prize, Turing test},
  language = {en},
  url      = {https://doi.org/10.1023/A:1011218925467},
  urldate  = {2024-02-20},
}

 
@Article{French2000,
  author     = {French, Robert M.},
  journal    = {Trends in Cognitive Sciences},
  title      = {The {Turing} {Test}: the first 50 years},
  year       = {2000},
  issn       = {1364-6613, 1879-307X},
  month      = mar,
  number     = {3},
  pages      = {115--122},
  volume     = {4},
  doi        = {10.1016/S1364-6613(00)01453-4},
  file       = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/10689346:text/html;Full Text PDF:http\://www.cell.com/article/S1364661300014534/pdf:application/pdf},
  language   = {English},
  pmid       = {10689346},
  publisher  = {Elsevier},
  shorttitle = {The {Turing} {Test}},
  url        = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(00)01453-4},
  urldate    = {2024-02-20},
}

 
@Article{Moor1976,
  author    = {Moor, James H.},
  journal   = {Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition},
  title     = {An {Analysis} of the {Turing} {Test}},
  year      = {1976},
  issn      = {0031-8116},
  number    = {4},
  pages     = {249--257},
  volume    = {30},
  file      = {JSTOR Full Text PDF:https\://www.jstor.org/stable/pdfplus/10.2307/4319091.pdf?acceptTC=true:application/pdf},
  publisher = {Springer},
  url       = {https://www.jstor.org/stable/4319091},
  urldate   = {2024-02-20},
}

 
@Article{PinarSaygin2000,
  author     = {Pinar Saygin, Ayse and Cicekli, Ilyas and Akman, Varol},
  journal    = {Minds and Machines},
  title      = {Turing {Test}: 50 {Years} {Later}},
  year       = {2000},
  issn       = {1572-8641},
  month      = nov,
  number     = {4},
  pages      = {463--518},
  volume     = {10},
  abstract   = {The Turing Test is one of the most disputed topics in artificial intelligence, philosophy of mind, and cognitive science. This paper is a review of the past 50 years of the Turing Test. Philosophical debates, practical developments and repercussions in related disciplines are all covered. We discuss Turing's ideas in detail and present the important comments that have been made on them. Within this context, behaviorism, consciousness, the `other minds' problem, and similar topics in philosophy of mind are discussed. We also cover the sociological and psychological aspects of the Turing Test. Finally, we look at the current situation and analyze programs that have been developed with the aim of passing the Turing Test. We conclude that the Turing Test has been, and will continue to be, an influential and controversial topic.},
  doi        = {10.1023/A:1011288000451},
  file       = {Full Text PDF:https\://link.springer.com/content/pdf/10.1023%2FA%3A1011288000451.pdf:application/pdf},
  keywords   = {chatbots, Chinese Room, consciousness, Imitation Game, intelligence, Loebner Contest, philosophy of mind, Turing Test},
  language   = {en},
  shorttitle = {Turing {Test}},
  url        = {https://doi.org/10.1023/A:1011288000451},
  urldate    = {2024-02-20},
}

 
@Article{LeCun2015,
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal   = {Nature},
  title     = {Deep learning},
  year      = {2015},
  issn      = {1476-4687},
  month     = may,
  number    = {7553},
  pages     = {436--444},
  volume    = {521},
  abstract  = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  copyright = {2015 Springer Nature Limited},
  doi       = {10.1038/nature14539},
  file      = {Full Text PDF:https\://www.nature.com/articles/nature14539.pdf:application/pdf},
  keywords  = {Computer science, Mathematics and computing},
  language  = {en},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/nature14539},
  urldate   = {2024-02-21},
}

 
@Article{Rumelhart1986,
  author    = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal   = {Nature},
  title     = {Learning representations by back-propagating errors},
  year      = {1986},
  issn      = {1476-4687},
  month     = oct,
  number    = {6088},
  pages     = {533--536},
  volume    = {323},
  abstract  = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  copyright = {1986 Springer Nature Limited},
  doi       = {10.1038/323533a0},
  file      = {Full Text PDF:https\://www.nature.com/articles/323533a0.pdf:application/pdf},
  keywords  = {Science, Humanities and Social Sciences, multidisciplinary, Science, multidisciplinary},
  language  = {en},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/323533a0},
  urldate   = {2024-02-21},
}

 
@Article{Hinton1992,
  author    = {Hinton, Geoffrey E.},
  journal   = {Scientific American},
  title     = {How {Neural} {Networks} {Learn} from {Experience}},
  year      = {1992},
  issn      = {0036-8733},
  number    = {3},
  pages     = {144--151},
  volume    = {267},
  file      = {JSTOR Full Text PDF:https\://www.jstor.org/stable/pdfplus/10.2307/24939221.pdf?acceptTC=true:application/pdf},
  publisher = {Scientific American, a division of Nature America, Inc.},
  url       = {https://www.jstor.org/stable/24939221},
  urldate   = {2024-02-21},
}

@Book{Lenat1990,
  author    = {Lenat, Douglas and Guha, RV},
  publisher = {Addison-Wesley},
  title     = {{Building Large Knowledge-Based Systems, Representation and Inference in the Cyc Project}},
  year      = {1990},
}

@Book{Zhang2023,
  author    = {Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
  publisher = {Cambridge University Press},
  title     = {Dive into deep learning},
  year      = {2023},
}

@Misc{Epoch2022,
  author = {Epoch},
  note   = {Accessed: 2024-03-21},
  title  = {Parameter, Compute and Data Trends in Machine Learning},
  year   = {2022},
  url    = {https://epochai.org/data/epochdb/visualization},
}

@Misc{Dean2019,
  author        = {Jeffrey Dean},
  title         = {The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1911.05289},
  primaryclass  = {cs.LG},
}

@Book{Mitchell1997,
  author    = {Mitchell, T.M.},
  publisher = {McGraw-Hill Education},
  title     = {Machine Learning},
  year      = {1997},
  isbn      = {9780070428072},
  series    = {McGraw-Hill international editions - computer science series},
  lccn      = {97007692},
  url       = {https://books.google.cl/books?id=xOGAngEACAAJ},
}

@Article{Wolpert1996,
  author    = {Wolpert, David H},
  journal   = {Neural computation},
  title     = {The lack of a priori distinctions between learning algorithms},
  year      = {1996},
  number    = {7},
  pages     = {1341--1390},
  volume    = {8},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…},
}

@Article{Hornik1989,
  author    = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal   = {Neural networks},
  title     = {Multilayer feedforward networks are universal approximators},
  year      = {1989},
  number    = {5},
  pages     = {359--366},
  volume    = {2},
  publisher = {Elsevier},
}

@Article{Hubel1959,
  author    = {Hubel, David H and Wiesel, Torsten N},
  journal   = {The Journal of physiology},
  title     = {Receptive fields of single neurones in the cat's striate cortex},
  year      = {1959},
  number    = {3},
  pages     = {574},
  volume    = {148},
  publisher = {Wiley-Blackwell},
}

@Article{Li2022,
  author    = {Li, Bin and Todo, Yuki and Tang, Zheng},
  journal   = {Brain Sciences},
  title     = {Artificial Visual System for Orientation Detection Based on Hubel--Wiesel Model},
  year      = {2022},
  number    = {4},
  pages     = {470},
  volume    = {12},
  publisher = {MDPI},
}

@Article{LeCun1989,
  author  = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, Richard and Hubbard, Wayne and Jackel, Lawrence},
  journal = {Advances in neural information processing systems},
  title   = {Handwritten digit recognition with a back-propagation network},
  year    = {1989},
  volume  = {2},
}

@Comment{jabref-meta: databaseType:bibtex;}
