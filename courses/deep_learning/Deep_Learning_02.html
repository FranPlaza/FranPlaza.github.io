<!DOCTYPE html>
<html lang="es"><head>
<script src="Deep_Learning_02_files/libs/clipboard/clipboard.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/tabby.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/popper.min.js"></script>
<script src="Deep_Learning_02_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Deep_Learning_02_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Deep_Learning_02_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">
<meta name="author" content="Francisco Plaza Vega">
<title>Deep Learning</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/reset.css">
<link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/reveal.css">
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
<link rel="stylesheet" href="Deep_Learning_02_files/libs/revealjs/dist/theme/quarto.css">
<link href="Deep_Learning_02_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
<link href="Deep_Learning_02_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
<style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
<style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center"><h1 class="title">Deep Learning</h1>
  <p class="subtitle">Unidad 2: Perceptrones Multicapa (MLP) y Deep Learning</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Francisco Plaza Vega 
</div>
<div class="quarto-title-author-email">
<a href="mailto:francisco.plaza.v@usach.cl">francisco.plaza.v@usach.cl</a>
</div>
        <p class="quarto-title-affiliation">
            Ingeniería en Estadística
          </p>
    </div>
</div>

</section><section><section id="redes-neuronales" class="title-slide slide level1 center" data-background-color="#00A499" data-number="1"><h1>
<span class="header-section-number">1</span> Redes Neuronales</h1>

</section><section class="slide level2"><div class="definition">
<ul>
<li class="fragment"><p>Una <span class="green">red neuronal artificial, <strong>ANN</strong></span> por sus siglas en inglés <span class="green"><em>artificial neural network</em></span> modelan la relación entre un conjunto de <span class="orange"><em>señales</em> de entrada</span> y una <span class="orange"><em>señal de salida</em></span> usando un modelo derivado desde nuestro entendimiento de cómo funciona un cerebro biológico ante estimulos externos.</p></li>
<li class="fragment"><p>Tal como un cerebro usa una red de células interconectadas llamadas <strong>neuronas</strong>, una <strong>red neuronal</strong> usa una red de neuronas artificiales o <strong>nodos</strong> para resolver problemas de aprendizaje.</p></li>
</ul>
</div>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/neuron.png"></p>
<figcaption>Neuronas biológicas</figcaption></figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/neuron_in_out.png"></p>
<figcaption>Impulso nervioso</figcaption></figure>
</div>
</div>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>La forma más común de representar la estructura de una red neuronal es mediante el uso de capas (<strong>layers</strong>), formadas a su vez por neuronas.</p></li>
<li class="fragment"><p>Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es refular la información que se propaga de una neurona a otra.</p></li>
</ul></section><section class="slide level2">
<img data-src="images/02_DNN/DL_infinite_layers.png" class="r-stretch quarto-figure-center"><p class="caption">Red neuronal artificial</p></section><section class="slide level2"><p>Para facilitar la comprensión de la estructura de las redes, es útil representar <span class="green">una red equivalente a un modelo de regresión lineal</span>:</p>
<p><span class="math display">\[y=w_1 x_1 +\dots+w_d x_d + b\]</span></p>
<ul>
<li class="fragment"><p>Cada neurona de la capa de entrada representa el<span class="green">valor de uno de los predictores</span>.</p></li>
<li class="fragment"><p>Las flechas representan los <span class="green">coeficientes de regresión</span>, que en términos de redes se llaman <span class="orange">pesos</span>, y la neurona de salida representa el <span class="orange">valor predicho</span>.</p></li>
<li class="fragment">
<p>Para que esta representación equivalga a la ecuación de un modelo lineal, faltan dos cosas:</p>
<ul>
<li class="fragment"><p>El <span class="green">sesgo (bias)</span> del modelo</p></li>
<li class="fragment"><p>Las operaciones de <span class="green">multiplicación y suma</span> que combinan el valor de los predictores con los pesos del modelo</p></li>
</ul>
</li>
<li class="fragment"><p>Cada neurona de la capa intermedia tiene un valor de bias, pero suele omitirse en las representaciones gráficas.</p></li>
<li class="fragment"><p>En cuanto a las operaciones matemáticas, es el elemento clave que ocurre dentro de las neuronas y conviene verlo con detalle.</p></li>
</ul></section></section><section><section id="neurona" class="title-slide slide level1 center" data-background-color="#00A499" data-number="2"><h1>
<span class="header-section-number">2</span> Neurona</h1>

</section><section class="slide level2"><ul>
<li class="fragment"><p>La neurona es la unidad funcional de los modelos de redes. Dentro de cada neurona ocurren simplemente dos operaciones: la <span class="green">suma ponderada de sus entradas</span> y la aplicación de una <span class="green">función de activación</span>.</p></li>
<li class="fragment"><p>En la primera parte, se multiplica cada valor de entrada <span class="math inline">\(x_i\)</span> por su peso asociado <span class="math inline">\(w_i\)</span> y se suman junto con el sesgo. Este es el valor neto de entrada a la neurona. A continuación, este valor se pasa por una función, conocida como <span class="orange"><strong>función de activación</strong>, que transforma el valor neto de entrada en un valor de salida</span>.</p></li>
<li class="fragment"><p>Si bien el valor que llega a la neurona, siempre es una combinación lineal, gracias a la función de activación, se pueden generar salidas muy diversas. Es en la <span class="orange">función de activación donde reside el potencial de los modelos de redes para aprender relaciones no lineales</span>.</p></li>
</ul></section><section class="slide level2">
<img data-src="images/02_DNN/neurona.png" class="r-stretch quarto-figure-center"><p class="caption">Neurona</p></section><section class="slide level2"><p>Lo anterior es la noción intuitiva de las redes neuronales artificiales, en términos mátemáticos:</p>
<div class="small">
<ul>
<li class="fragment">El valor neto de entrada a una neurona es la suma de los valores que le llegan, ponderados por el peso de las conexiones, más el sesgo:</li>
</ul>
<p><span class="math display">\[Input = \sum_{i=1}^{n} x_i w_i + b\]</span></p>
<ul>
<li class="fragment">En lugar de utilizar la sumatoria, este operación usualmente se presenta como un producto matricial, donde <span class="math inline">\(X\)</span> representa el vector de los valores de entrada y <span class="math inline">\(W\)</span> el vector de pesos:</li>
</ul>
<p><span class="math display">\[Input = XW + b\]</span></p>
</div>
</section><section class="slide level2"><p>A este valor se le aplica una <span class="green">función de activación <span class="math inline">\(g\)</span></span> que lo transforma en lo que se conoce como el <span class="orange">valor de activación <span class="math inline">\(a\)</span></span>, que es lo que finalmente sale de la neurona.</p>
<p><span class="math display">\[a=g(Input)=g(XW+b)\]</span></p>
<ul>
<li class="fragment"><p>Para la capa de entrada, donde únicamente se quiere incorporar el valor de los predictores, la <span class="orange">función de activación es la unidad</span>, es decir, sale lo mismo que entra.</p></li>
<li class="fragment"><p>En la capa de salida, la función de activación utilizada <span class="green">suele ser la identidad para problemas de regresión</span>, mientras que en <span class="green">problemas de clasificación, se aplican otras funciones</span>.</p></li>
</ul></section></section><section><section id="función-de-activación" class="title-slide slide level1 center" data-background-color="#00A499" data-number="3"><h1>
<span class="header-section-number">3</span> Función de activación</h1>

</section><section class="slide level2"><div class="definition">
<ul>
<li class="fragment"><p>Las funciones de activación controlan en gran medida qué información se propaga desde una capa a la siguiente (<span class="green"><em>forward propagation</em></span>).</p></li>
<li class="fragment"><p>Estas funciones convierten el valor neto de entrada a la neurona (combinación de los input, pesos y sesgo) en un nuevo valor. Gracias a combinar <span class="orange"><strong>funciones de activación no lineales con múltiples capas</strong></span>, los modelos de redes son capaces de aprender relaciones <span class="orange"><strong>no lineales</strong></span>.</p></li>
<li class="fragment"><p>La gran mayoría de funciones de activación <span class="green">convierten el valor de entrada neto de la neurona en un valor dentro del rango <span class="math inline">\((0, 1)\)</span> o <span class="math inline">\((-1, 1)\)</span></span>. Cuando el valor de activación de una neurona (salida de su función de activación) es cero, <span class="green">se dice que la neurona está <strong>inactiva</strong></span>, ya que no pasa ningún tipo de información a las siguientes neuronas.</p></li>
</ul>
</div>
</section><section id="tipos-de-funciones-de-activación" class="slide level2" data-number="3.1"><h2>
<span class="header-section-number">3.1</span> Tipos de funciones de activación</h2>
<p>Existen <span class="green">muchas funciones de activación</span> utilizadas en la práctica, en lo que sigue mencionamos sólo algunas de ellas:</p>
<div class="small">
<ul>
<li class="fragment"><p>Sigmoide</p></li>
<li class="fragment"><p>Tangente hiperbólica</p></li>
<li class="fragment"><p><em>Rectified Linear Unit</em> (ReLU)</p></li>
<li class="fragment"><p><em>Gaussian Error Linear Unit</em> (GELU)</p></li>
<li class="fragment"><p>También hay otras como: función lineal, gaussiana, linear saturada, etc.</p></li>
</ul>
</div>
</section><section class="slide level2"><h3 data-number="3.1.1" id="sigmoide">
<span class="header-section-number">3.1.1</span> Sigmoide</h3>
<div class="definition">
<p>La función sigmoide transforma valores en la recta real a valores en el rango <span class="math inline">\([0, 1]\)</span>:</p>
<p><span class="math display">\[sigmoid(x)=\dfrac{1}{1+\exp(-x)}\]</span></p>
</div>

<img data-src="images/02_DNN/sigmoid.png" class="r-stretch quarto-figure-center"><p class="caption">Sigmoid</p></section><section class="slide level2"><ul>
<li class="fragment"><p>Aunque la función de activación sigmoide <span class="orange">se utilizó mucho en los inicios</span> de los modelos de redes, en la actualidad, suele preferirse la función ReLU.</p></li>
<li class="fragment"><p>Un caso en el que la función de activación sigmoide sigue siendo la función utilizada por defecto es en las neuronas de la capa de salida de los <span class="orange">modelos de clasificación binaria</span>, ya que su salida puede interpretarse como probabilidad.</p></li>
</ul></section><section class="slide level2"><h3 data-number="3.1.2" id="tangente-hiperbólica">
<span class="header-section-number">3.1.2</span> Tangente hiperbólica</h3>
<div class="definition">
<p>La función de activación <code>Tanh</code>, se comporta de forma similar a la función sigmoide, pero su salida está acotada en el rango <span class="math inline">\([-1, 1]\)</span>:</p>
<p><span class="math display">\[\tanh(x)=\dfrac{1-\exp(-2x)}{1+\exp(-2x)}\]</span></p>
</div>

<img data-src="images/02_DNN/tanh.png" class="r-stretch quarto-figure-center"><p class="caption">Tangente hiperbólica</p></section><section class="slide level2"><h3 data-number="3.1.3" id="rectified-linear-unit-relu">
<span class="header-section-number">3.1.3</span> Rectified linear unit (ReLU)</h3>
<div class="definition">
<p>La función de activación <code>ReLu</code> aplica una transformación no lineal muy simple, <span class="green">activa la neurona solo si el input está por encima de cero</span>. Mientras el valor de entrada está por debajo de cero, el valor de salida es cero, pero cuando es superior, el valor de salida aumenta de forma lineal con el de entrada.</p>
<p><span class="math display">\[ReLU(x)=\max (0,x)\]</span></p>
</div>

<img data-src="images/02_DNN/relu.png" class="r-stretch quarto-figure-center"><p class="caption">Rectified linear unit</p></section><section class="slide level2"><ul>
<li class="fragment"><p>De esta forma, la función de activación <span class="orange">retiene únicamente los valores positivos</span> y descarta los negativos dándoles una activación de cero.</p></li>
<li class="fragment"><p>ReLU es con diferencia la <span class="orange">función de activación más empleada</span> por sus buenos resultados en aplicaciones diversas. La razón de esto reside en el comportamiento de su derivada (gradiente), que es cero o constante.</p></li>
</ul></section><section class="slide level2"><h3 data-number="3.1.4" id="gaussian-error-linear-unit-gelu">
<span class="header-section-number">3.1.4</span> Gaussian Error Linear Unit (GELU)</h3>
<div class="definition">
<p>Se considera una <span class="green">mejora sobre las funciones de activación tradicionales</span> como ReLU, debido a sus propiedades suaves y no lineales.</p>
<p><span class="math display">\[ GELU(x) = x \cdot \Phi (x)\]</span> donde <span class="math inline">\(Phi(x)\)</span> representa la CDF de la distribución normal estándar.</p>
</div>

<img data-src="images/02_DNN/GELU.png" class="r-stretch quarto-figure-center"><p class="caption">Gaussian Error Linear Unit</p></section><section class="slide level2"><ul>
<li class="fragment"><p>La GELU permite que las señales pasen a través de ella de manera similar a ReLU, pero con una <span class="orange">transición más suave</span>.</p></li>
<li class="fragment"><p>En lugar de cortar directamente en cero como en ReLU (donde todos los valores negativos se convierten en cero), la GELU modula la señal de manera que los <span class="orange">valores pequeños se atenúan gradualmente</span> hacia cero, y los <span class="orange">valores positivos pasan con una transformación</span> similar a la normal.</p></li>
<li class="fragment"><p>La función GELU se ha vuelto <span class="orange">popular en modelos de deep learning avanzados</span>, como modelos de procesamiento de lenguaje natural, GAN, <a href="https://www.sciencedirect.com/science/article/pii/S2666651022000146">Transformers</a>, entre otros.</p></li>
</ul></section><section class="slide level2"><h3 data-number="3.1.5" id="funciones-de-activación-y-sus-usos">
<span class="header-section-number">3.1.5</span> Funciones de activación y sus usos</h3>
<div class="r-stack">
<p><img data-src="images/02_DNN/activation_functions_eq.png" class="fragment"></p>
<p><img data-src="images/02_DNN/activation_functions_use.png" class="fragment"></p>
</div>
</section><section class="slide level2">
<img data-src="images/02_DNN/activations.png" class="r-stretch quarto-figure-center"><p class="caption">Ejemplos de perceptrones y funciones de activación</p></section></section><section><section id="función-de-coste-loss-function" class="title-slide slide level1 center" data-background-color="#00A499" data-number="4"><h1>
<span class="header-section-number">4</span> Función de coste (loss function)</h1>

</section><section class="slide level2"><div class="definition">
<div>
<ul>
<li><p>El objetivo del modelo es <span class="green">predecir un valor real</span> o <span class="green">clasificar datos</span>.</p></li>
<li><p>Existirán <span class="orange">errores en la predicción</span>.</p></li>
<li><p>Para la <span class="orange">cuantificación de dicho error</span>, utilizaremos una <span class="green">función de coste (o pérdida)</span>.</p></li>
</ul>
</div>
</div>
<p></p>
<div class="fragment">
<div class="definition">
<p><span class="blue">Definición</span></p>
<p>Dado un set de datos <span class="math inline">\(D(\mathbf{X}, \mathbf{Y})\)</span>, con <span class="math inline">\(N\)</span> puntos y un modelo <span class="math inline">\(M\)</span>, una función general de coste está dada por</p>
<p><span class="math display">\[L(M) = \sum_{i=1}^{N} d\left[ f(x(i);M), y(i) \right]\]</span></p>
<p>con <span class="math inline">\(d[\cdot]\)</span> la distancia entre los valores predichos y los verdaderos, <span class="math inline">\(x(i)\)</span> los <span class="math inline">\(i\)</span>-ésimos valores o clases predichas y <span class="math inline">\(y(i)\)</span> los <span class="math inline">\(i\)</span>-ésimos valores o clases verdaderas.</p>
</div>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>La <span class="green">función de coste (<span class="math inline">\(l\)</span>)</span>, también llamada función de pérdida, <span class="green"><em>loss function</em> o <em>cost function</em></span>, es la encargada de <span class="orange"><strong>cuantificar</strong> la distancia entre el valor real y el valor predicho</span> por la red, en otras palabras, <strong>mide cuánto se equivoca la red al realizar predicciones</strong>.</p></li>
<li class="fragment"><p>En la mayoría de casos, la función de coste devuelve valores positivos. <span class="green">Cuanto más próximo a cero es el valor de coste, mejor son las predicciones</span> de la red (menor error), siendo cero cuando las predicciones se corresponden exactamente con el valor real.</p></li>
</ul>

<img data-src="images/02_DNN/goals.png" class="r-stretch quarto-figure-center"><p class="caption">Distintos objetivos de un modelo.</p></section><section class="slide level2"><ul>
<li class="fragment"><p>La función de coste <span class="green">puede calcularse para una única observación o para un conjunto de datos (normalmente promediando el valor de todas las observaciones)</span>. Es el segundo caso el que se utiliza para dirigir el entrenamiento de los modelos.</p></li>
<li class="fragment"><p>Dependiendo del tipo de problema, regresión o clasificación, es necesario utilizar una función de coste u otra. En problemas de <span class="orange">regresión, las más utilizadas son el error cuadrático medio y el error absoluto medio</span>. En problemas de [clasificación suele emplearse la función <em>log loss</em>, también llamada <em>logistic loss</em> o <em>cross-entropy loss</em>]{orange}.</p></li>
</ul></section><section id="funciones-de-coste-para-regresión" class="slide level2" data-number="4.1"><h2>
<span class="header-section-number">4.1</span> Funciones de coste para regresión</h2>
<div class="alert">
<p>Las funciones de coste más comunes para regresión:</p>
<div class="small">
<ul>
<li class="fragment">Error cuadrático medio:</li>
</ul>
<p><span class="math display">\[L_{sq}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}\left( \widehat{y}^{(i)}-y^{(i)}\right)^{2}\]</span></p>
<ul>
<li class="fragment">Error medio absoluto:</li>
</ul>
<p><span class="math display">\[L_{abs}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}|\widehat{y}^{(i)}-y^{(i)}|\]</span></p>
</div>
</div>
</section><section class="slide level2"><h3 data-number="4.1.1" id="error-cuadrático-medio">
<span class="header-section-number">4.1.1</span> Error cuadrático medio</h3>
<div class="definition">
<p>El <span class="green">error cuadrático medio (<em>mean squared error</em>, MSE) es la función de coste más utilizada en problemas de regresión</span>. Para una determinada observación <span class="math inline">\(i\)</span>, el error cuadrático se calcula como la diferencia al cuadrado entre el valor predicho <span class="math inline">\(\hat{y}\)</span> y el valor real <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[l_{sq}^{(i)}(w,b)=\left( \widehat{y}^{(i)}-y^{(i)}\right)^2\]</span></p>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>Las funciones de coste <span class="orange">suelen escribirse con la notación <span class="math inline">\(l(w,b)\)</span></span> para hacer referencia a que su valor depende de los pesos y el sesgo del modelo, ya que son estos los que determinan el valor de las predicciones <span class="math inline">\(\widehat{y}^{(i)}\)</span>.</p></li>
<li class="fragment"><p>Con frecuencia, esta función de coste <span class="orange">se encuentra multiplicada por <span class="math inline">\(\dfrac{1}{2}\)</span></span>, esto es simplemente por conveniencia matemática para simplificar el cálculo de su derivada.</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[L_{sq}^{(i)}(w,b)=\dfrac{1}{2}\left( \widehat{y}^{(i)}-y^{(i)}\right)^2\]</span></p>
</div>
</section><section class="slide level2"><p>Para <span class="orange">cuantificar el error que comete el modelo en todo un conjunto de datos</span>, por ejemplo los de entrenamiento, se promedia el error de todas las <span class="math inline">\(N\)</span> observaciones.</p>
<div class="fragment">
<p><span class="math display">\[L_{sq}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}l^{(i)}(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}\left( \widehat{y}^{(i)}-y^{(i)}\right)^{2}\]</span></p>
</div>
<div class="fragment">
<div class="alert">
<p>Cuando un modelo se <span class="orange">entrena utilizando el error cuadrático medio como función de coste, está aprendiendo a <strong>predecir la media de la variable respuesta</strong></span>.</p>
</div>
</div>
</section><section class="slide level2"><h3 data-number="4.1.2" id="error-medio-absoluto">
<span class="header-section-number">4.1.2</span> Error medio absoluto</h3>
<div class="definition">
<p>El <span class="green">error medio absoluto (<em>mean absolute error</em>, MAE)</span> consiste en <span class="orange">promediar el error absoluto de las predicciones</span>.</p>
<p><span class="math display">\[L(w,b)=\dfrac{1}{n}\sum_{i=1}^{n}|\widehat{y}^{(i)}-y^{(i)}|\]</span></p>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>El error medio absoluto es <span class="orange">más robusto frente a <em>outliers</em></span> que el error cuadrático medio.</p></li>
<li class="fragment"><p>Esto significa que, el <span class="orange">entrenamiento del modelo, se ve menos influenciado por datos anómalos</span> que pueda haber en el conjunto de entrenamiento.</p></li>
<li class="fragment"><p>Cuando un modelo se entrena utilizando el error absoluto medio como función de coste, <span class="orange">está aprendiendo a <strong>predecir la mediana de la variable respuesta</strong></span>.</p></li>
</ul></section><section id="funciones-de-coste-para-clasificación" class="slide level2" data-number="4.2"><h2>
<span class="header-section-number">4.2</span> Funciones de coste para clasificación</h2>
<div class="alert">
<div class="small">
<p>Las funciones de coste más comunes para problemas de clasificación:</p>
<ul>
<li class="fragment">Entropia cruzada binaria (Binary crossentropy):</li>
</ul>
<p><span class="math display">\[L_{bc}(M) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y^{(i)} \cdot log(\hat{y}^{(i)}) + (1 - y^{(i)}) \cdot log(1 - \hat{y}^{(i)}) \right]\]</span></p>
<ul>
<li class="fragment">Entropía cruzada categórica (Categorical crossentropy):</li>
</ul>
<p><span class="math display">\[L_{bc}(M) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} \left[ y^{(i,j)} \cdot log(\hat{y}^{(i,j)}) \right], \]</span></p>
<p>donde <span class="math inline">\(y^{(i,j)} =1\)</span>, si la clase de <span class="math inline">\(y^{(i,j)}\)</span> es <span class="math inline">\(j\)</span> y 0 en cualquier otro caso, <span class="math inline">\(\hat{y}^{(i,j)}\)</span> es la probabilidad entregada por el modelo para que la <span class="math inline">\(i\)</span>-ésima observación pertenezca a la <span class="math inline">\(j\)</span>-ésima clase.</p>
</div>
</div>
</section></section><section><section id="múltiples-capas" class="title-slide slide level1 center" data-background-color="#00A499" data-number="5"><h1>
<span class="header-section-number">5</span> Múltiples capas</h1>

</section><section class="slide level2"><div class="definition">
<ul>
<li class="fragment"><p>El modelo de red neuronal con <span class="green">una única capa (<strong>single-layer perceptron</strong>)</span>, aunque supuso un gran avance en el campo del <em>machine learning</em>, sólo <span class="orange">es capaz de aprender patrones sencillos</span>.</p></li>
<li class="fragment"><p>Para superar esta limitación, los investigadores descubrieron que, combinando <span class="green">múltiples capas ocultas</span>, la red puede aprender relaciones mucho más <span class="orange">complejas entre los predictores y la variable de respuesta</span>.</p></li>
<li class="fragment"><p>A esta estructura se le conoce como <span class="green"><strong>perceptrón multicapa</strong> o <strong>multilayer perceptron</strong> (MLP)</span>, y puede considerarse como el primer modelo de <strong>deep learning</strong>.</p></li>
</ul>
</div>
</section><section class="slide level2"><ul>
<li class="fragment"><p>La estructura de <span class="green">un perceptrón multicapa consta de varias capas ocultas</span>. Cada neurona está conectada a todas las neuronas de la capa anterior y a las de la capa posterior.</p></li>
<li class="fragment"><p>Aunque no es estrictamente necesario, todas las neuronas que forman parte de <span class="orange">una misma capa suelen emplear la misma función de activación</span>.</p></li>
<li class="fragment"><p>Combinando <span class="orange">múltiples capas ocultas</span> y <span class="orange"><strong>funciones de activación no lineales</strong></span>, los modelos de redes pueden aprender prácticamente cualquier patrón. De hecho, está demostrado que, con <span class="green">suficientes neuronas, un MLP es un aproximador universal</span> para cualquier función.</p></li>
</ul></section><section class="slide level2">
<img data-src="images/02_DNN/DL_infinite_layers.png" class="r-stretch quarto-figure-center"><p class="caption">perceptrón multicapa</p></section><section id="teorema-de-aproximación-universal" class="slide level2" data-number="5.1"><h2>
<span class="header-section-number">5.1</span> Teorema de aproximación universal</h2>
<div class="definition">
<blockquote>
<p><em>Las redes neuronales profundas funcionan tan bien porque son <span class="green">aproximadores universales de funciones</span>. En particular, sabemos que para cualquier función continua que no sea constante, acotada y monótonamente creciente, existe una red feedforward con una capa de salida lineal y al menos una capa oculta con cualquier función de activación de “compresión” (como la sigmoide logística) que puede aproximar esta función con cualquier error no nulo deseado.</em></p>
</blockquote>
<p><span class="citation" data-cites="Hornik1989">Hornik, Stinchcombe, y White (<a href="#/referencias" role="doc-biblioref" onclick="">1989</a>)</span></p>
</div>
<p> </p>
<div class="definition">
<blockquote>
<p><em>Una red feedforward con una sola capa es suficiente para representar cualquier función, pero la capa puede ser inmanejablemente grande y puede fallar en aprender y generalizar correctamente.</em></p>
</blockquote>
<p><span class="citation" data-cites="Goodfellow2016">Goodfellow, Bengio, y Courville (<a href="#/referencias" role="doc-biblioref" onclick="">2016</a>)</span></p>
</div>
</section><section class="slide level2"><div class="example">
<p><span class="green">Tarea</span> Busque información sobre el <span class="blue">Teorema de aproximación universal</span></p>
</div>
</section></section><section><section id="entrenamiento" class="title-slide slide level1 center" data-background-color="#00A499" data-number="6"><h1>
<span class="header-section-number">6</span> Entrenamiento</h1>

</section><section class="slide level2"><div class="definition">
<p>El <span class="green">proceso de entrenamiento</span> de una red neuronal consiste en <span class="orange">ajustar el valor de los pesos y sesgo de tal forma que, las predicciones que se generen, tengan el menor error posible</span>. Gracias a esto, el modelo es capaz de identificar qué predictores tienen mayor influencia y de qué forma están relacionados entre ellos y con la variable de respuesta.</p>
</div>
</section><section class="slide level2"><div class="alert">
<p>La idea intuitiva de cómo entrenar una red neuronal es la siguiente:</p>
<div class="small">
<ol type="1">
<li class="fragment"><p>Iniciar la red con valores aleatorios de los pesos y sesgo.</p></li>
<li class="fragment"><p>Para cada observación de entrenamiento, calcular el error que comete la red al hacer su predicción. Promediar los errores de todas las observaciones.</p></li>
<li class="fragment"><p>Identificar la responsabilidad que ha tenido cada peso y sesgo en el error de las predicciones.</p></li>
<li class="fragment"><p>Modificar ligeramente los pesos y sesgos de la red (de forma proporcional a su responsabilidad en el error) en la dirección correcta para que se reduzca el error.</p></li>
<li class="fragment"><p>Repetir los pasos 2, 3, 4 y 5 hasta que la red sea suficientemente buena.</p></li>
</ol>
</div>
</div>
<p></p>
<p>Si bien, la idea parece sencilla, el alcanzar una forma de implementarla ha requerido la combinación de múltiples métodos matemáticos, en particular, <span class="green"><em>backward</em> y <em>forward propagation</em></span></p>
</section><section class="slide level2"><div class="alert">
<div>
<ul>
<li><p>En el proceso de entrenamiento, se <span class="orange">busca el mejor conjunto de parámetros</span> para <span class="orange">minimizar alguna de las funciones de coste</span> o pérdida.</p></li>
<li><p>La verdadera forma de la función de pérdida sólo puede ser construída si se tuviesen datos infinitos. Al ser finita la cantidad de datos que se tiene, la <span class="orange">función de pérdida obtenida no reflejará la verdadera forma de la función de pérdida</span>.</p></li>
</ul>
</div>
</div>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/training.png" style="width:80.0%"></p>
<figcaption>Minimización de una función de pérdida para un proceso de entrenamiento de 500 épocas</figcaption></figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/training_hyperplane.png"></p>
<figcaption>Hiperplano que representa la función de pérdida con 2 parámetros.</figcaption></figure>
</div>
</div>
</div>
</section><section class="slide level2">
<img data-src="images/02_DNN/training_epochs.png" class="r-stretch quarto-figure-center"><p class="caption">Resultados de predicción de un modelo a través de las épocas</p></section><section id="definiciones" class="slide level2" data-number="6.1"><h2>
<span class="header-section-number">6.1</span> Definiciones</h2>
<div class="definition">
<p>Es un proceso iterativo que minimiza una función de pérdida específica</p>
<p><span class="math display">\[\mbox{Min}_{\overline{W}} \left \{ L = \sum_{(\overline{X},y) \in D} L(y, g(w_0 + \overline{WX})) = \sum_{(\overline{X},y) \in D} L(y, \hat{y}) \right \}\]</span></p>
</div>
<ul>
<li class="fragment"><p>El algoritmo toma los ejemplos del conjunto de entrenamiento en orden aleatorio y ajusta los pesos hasta que se alcanza algún criterio de convergencia.</p></li>
<li class="fragment"><p>En la mayoría de los casos, los pesos son actualizados mediante una secuencia de gradiente descendiente</p></li>
</ul>
<div class="fragment">
<div>
<p><span class="math display">\[\overline{W}_{t+1} = \overline{W}_{t} - \alpha \bigtriangledown  L\]</span></p>
<p>donde <span class="math inline">\(\alpha\)</span> es el parámetro de aprendizaje (<span class="green">tasa de aprendizaje</span>) y <span class="math inline">\(\bigtriangledown L\)</span> es el gradiente descendiente de la función de pérdida. La idea es acercarse hacia el mínimo local, en contra del gradiente.</p>
</div>
</div>
</section><section id="decenso-del-gradiente" class="slide level2" data-number="6.2"><h2>
<span class="header-section-number">6.2</span> Decenso del gradiente</h2>
<p>El proceso de entrenamiento está basado en el <span class="green">algoritmo de optimización de decenso del gradiente (<em>Gradient descent optimization algorithm</em>)</span>. Es decir, los pesos de las neuronas son actualizados utilizando el <span class="orange">gradiente de la función de pérdida</span></p>
<p><span class="math display">\[\overline{W}_{t+1} = \overline{W}_{t} - \alpha \bigtriangledown  L\]</span></p>
<ul>
<li class="fragment"><p>El gradiente de la función de pérdida <span class="orange">describe la pendiente</span>, es decir, la dirección que we debe utilizar para minimizar el error.</p></li>
<li class="fragment"><p><span class="math inline">\(\alpha\)</span> representa el <span class="orange">parámetro de aprendizaje</span>, y debemos configurarlo con cuidado.</p></li>
</ul>
<div class="fragment">
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/learning_rate.png" class="quarto-figure quarto-figure-center" height="300"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/local_global_minima.png" class="quarto-figure quarto-figure-center" height="300"></p>
</figure>
</div>
</div>
</div>
</div>
</section><section class="slide level2"><p>Se necesitan múltiples pasos porque sólo se calcula la dirección de la minimización, y esto no necesariamente indica el punto mínimo.</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/loss_circular.png"></p>
<figcaption>Escenario ideal, la dirección del decenso del gradiente apunta hacia el mínimo de la función de pérdida.</figcaption></figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/loss_elliptical.png"></p>
<figcaption>Escenario más probable, la dirección apunta hacia una disminución del error de la función, pero no hacia el mínimo.</figcaption></figure>
</div>
</div>
</div>
</section><section class="slide level2"><p>Volviendo al <span class="green">proceso <em>intuitivo</em> del entrenamiento</span> que vimos anteriormente, ahora formalizando un poco:</p>
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/algorithm_training.png" class="quarto-figure quarto-figure-center" height="600"></p>
</figure>
</div>
</section><section id="backpropagation" class="slide level2" data-number="6.3"><h2>
<span class="header-section-number">6.3</span> Backpropagation</h2>
<div class="definition">
<p><span class="green"><em>Backpropagation</em></span> es el algoritmo que permite cuantificar la influencia que tiene cada peso y bias en las predicciones de la red. Para conseguirlo, hace uso de la <span class="orange"><strong>regla de la cadena</strong></span> para calcular el gradiente, que no es más que el vector formado por las derivadas parciales de una función.</p>
</div>
<p>En el <span class="green">caso de las redes MLP</span>, la derivada parcial del error respecto a un parámetro (peso o sesgo) mide <span class="orange">cuánta <em>responsabilidad</em> ha tenido ese parámetro</span> en el error cometido. Gracias a esto, se puede identificar qué pesos de la red hay que modificar para mejorarla. El siguiente paso necesario, es determinar cuánto y cómo modificarlos (optimización).</p>
</section><section class="slide level2"><h3 data-number="6.3.1" id="prepocesamiento-de-variables">
<span class="header-section-number">6.3.1</span> Prepocesamiento de variables</h3>
<p>A la hora de entrenar modelos basados en redes neuronales, y en general modelos de <em>Deep Learning</em>, es <span class="green">necesario aplicar</span> a los datos, al menos, alguna de estas transformaciones:</p>
<div class="columns">
<div class="column">
<p><span class="green"><strong>Codificación numérica (numerical encoding)</strong></span>: Variables ordinales son codificadas en números enteros.</p>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/numeric_encoding.png" class="quarto-figure quarto-figure-center" height="250"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column">
<p><span class="green"><strong>Binarización (one hot encoding) de las variables categóricas</strong></span>: La binarización consiste en crear nuevas variables <em>dummy</em> con cada uno de los niveles de las variables cualitativas. Este proceso es el mismo realizado en modelos lineales.</p>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/one_hot_encoding.png" class="quarto-figure quarto-figure-center" height="250"></p>
</figure>
</div>
</div>
</div>
</section><section class="slide level2"><p><span class="green"><strong>Estandarización y escalado de variables numéricas</strong></span>: Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Para ello, en general centramos los datos, y estandarizamos o reescalamos entre 0 y 1.</p>
<div class="columns">
<div class="column">
<p>Estandarización: <span class="math display">\[ x_{std}^{(i)} = \frac{x^{(i)} - \mu_{x}}{\sigma_{x}} \]</span></p>
</div><div class="column">
<p>Normalización (<em>Min-Max Scaling</em>): <span class="math display">\[x_{norm}^{(i)} = \frac{x^{(i)} - \mathbf{x}_{min}}{\mathbf{x}_{max} - \mathbf{x}_{min}}\]</span></p>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/norm_std.jpg" class="quarto-figure quarto-figure-center" height="400"></p>
</figure>
</div>
</section></section><section><section id="hiperparámetros" class="title-slide slide level1 center" data-background-color="#00A499" data-number="7"><h1>
<span class="header-section-number">7</span> Hiperparámetros</h1>

</section><section class="slide level2"><div class="definition">
<p>La gran <span class="green">“flexibilidad”</span> que tienen las redes neuronales es un arma de doble filo. Por un lado, son capaces de generar modelos que aprenden relaciones muy complejas, sin embargo, sufren fácilmente el <span class="orange">problema de sobreajuste (<em>overfitting</em>)</span> lo que los <strong>incapacita al tratar de predecir nuevas observaciones</strong>.</p>
<p>La forma de minimizar este problema y conseguir modelos útiles pasa por <span class="green">configurar de forma adecuada sus hiperparámetros</span>. Son muchos los hiperparámetros de un modelo basado en redes y su nomenclatura varía de unas implementaciones a otras, sin embargo, los de mayor impacto siempre están presentes:</p>
</div>
<ul>
<li class="fragment"><p>Número y tamaño de capas</p></li>
<li class="fragment"><p><em>Learning rate</em></p></li>
<li class="fragment"><p>Algoritmo de optimización</p></li>
<li class="fragment"><p>Regularización</p></li>
</ul></section><section id="número-y-tamaño-de-capas" class="slide level2" data-number="7.1"><h2>
<span class="header-section-number">7.1</span> Número y tamaño de capas</h2>
<div class="definition">
<p>La arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.</p>
</div>
<ul>
<li class="fragment"><p>La <span class="green">capa de entrada y salida son sencillas de establecer</span>. <span class="orange">La capa de entrada tiene tantas neuronas como predictores</span> y la <span class="orange">capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación</span>. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento.</p></li>
<li class="fragment"><p>El usuario suele <span class="orange">especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas</span>.</p></li>
<li class="fragment"><p>Cuantas <span class="orange">más neuronas y capas, mayor la complejidad</span> de las relaciones que puede aprender el modelo (Teorema de la Aproximación Universal, <span class="citation" data-cites="Hornik1989">(<a href="#/referencias" role="doc-biblioref" onclick="">Hornik, Stinchcombe, y White 1989</a>)</span>). Sin embargo, dado que cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento.</p></li>
</ul></section><section id="learning-rate" class="slide level2" data-number="7.2"><h2>
<span class="header-section-number">7.2</span> Learning rate</h2>
<div class="definition">
<p>El <span class="green"><em>learning rate</em> o tasa de aprendizaje</span> establece cuan rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interacciona con el resto de hiperparámetros. Si el <em>learning rate</em> es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse.</p>
</div>
<p>Algunas de las recomendaciones <strong>heurísticas</strong> basadas en prueba y error son:</p>
<ul>
<li class="fragment"><p>Utilizar un <em>learning rate</em> lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.</p></li>
<li class="fragment"><p>No utilizar un valor constante de <em>learning rate</em> durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final.</p></li>
</ul></section><section id="algoritmo-de-optimización" class="slide level2" data-number="7.3"><h2>
<span class="header-section-number">7.3</span> Algoritmo de optimización</h2>
<div class="definition">
<p>El <span class="green"><em>descenso de gradiente</em> y el <em>descenso de gradiente estocástico</em> fueron de los primeros métodos de optimización utilizados para entrenar modelos de redes neuronales</span>. Ambos utilizan directamente el gradiente para dirigir la optimización. Pronto se vio que esto genera problemas a medida que las redes aumentan de tamaño (neuronas y capas). En muchas regiones del espacio de búsqueda, el gradiente es muy próximo a cero, lo que hace que la optimización quede estancada. Para evitar este problema, se han desarrollado modificaciones del descenso de gradiente capaces de adaptar el <em>learning rate</em> en función del gradiente y subgradiente. De esta forma, el proceso de aprendizaje se ralentiza o acelera dependiendo de las características de la región del espacio de búsqueda en el que se encuentren.</p>
</div>
<p>Aunque existen multitud de adaptaciones, suele recomendarse:</p>
<ul>
<li class="fragment"><p>Para <span class="green">conjuntos de datos pequeños</span>: <code>l-bfgs</code> (<em>limited memory bfgs</em>)</p></li>
<li class="fragment"><p>Para <span class="green">conjuntos de datos grandes</span>: <code>adam</code> o <code>rmsprop</code> (<em>root mean square propagation</em>)</p></li>
</ul>
<p>La <span class="green">elección del algoritmo de optimización</span> puede tener un <span class="green">impacto notable en el aprendizaje</span> de los modelos, sobre todo en <em>deep learning</em>.</p>
</section><section id="regularización" class="slide level2" data-number="7.4"><h2>
<span class="header-section-number">7.4</span> Regularización</h2>
<div class="definition">
<p>Los métodos de regularización tienen el objetivo de reducir el sobreajuste (<em>overfitting</em>) de los modelos. Un modelo con sobreajuste memoriza los datos de entrenamiento pero es incapaz de predecir correctamente nuevas observaciones.</p>
<p>Los modelos de redes neuronales pueden considerarse como <strong>modelos sobre parametrizados</strong>, por lo tanto, las estrategias de regularización son fundamentales.</p>
</div>
<p>De entre las muchas que existen, destacan:</p>
<ul>
<li class="fragment"><p><em>regularization</em> <strong>L1</strong> y <strong>L2</strong> (<em>weight decay</em>)</p></li>
<li class="fragment"><p><em>dropout</em></p></li>
<li class="fragment"><p><em>data augmentation</em></p></li>
<li class="fragment"><p><em>early stopping</em></p></li>
</ul></section><section class="slide level2"><h3 data-number="7.4.1" id="regularización-l1-lasso">
<span class="header-section-number">7.4.1</span> Regularización L1 (Lasso)</h3>
<ul>
<li class="fragment"><p>La regularización L1 agrega una penalización igual al valor absoluto de la magnitud de los coeficientes al costo total. Esto puede resultar en coeficientes que sean exactamente cero, lo que significa que la regularización L1 puede producir modelos con algunas características completamente descartadas, siendo útil para la selección de características.</p></li>
<li class="fragment"><p>Matemáticamente, se agrega un término adicional al coste que es igual a la suma de los valores absolutos de los coeficientes multiplicados por un parámetro de regularización lambda.</p></li>
</ul>
<div>
<p><span class="math display">\[ L(w)_{L1} = L(w) \text{ base sin regularización} + \lambda \sum_{i=1}^{n} |w_i| \]</span></p>
<p>donde <span class="math inline">\(\lambda\)</span> es el parámetro de regularización que controla la fuerza de la regularización y <span class="math inline">\(w_i\)</span> son los parámetros del modelo.</p>
</div>
</section><section class="slide level2"><h3 data-number="7.4.2" id="regularización-l2-ridge">
<span class="header-section-number">7.4.2</span> Regularización L2 (Ridge)</h3>
<ul>
<li class="fragment"><p>La regularización L2 añade una penalización igual al cuadrado de la magnitud de los coeficientes. Esto tiene el efecto de penalizar los valores extremos de los pesos, forzando a que sean relativamente pequeños, lo cual simplifica el modelo pero sin llevar a cabo una selección de características explícita.</p></li>
<li class="fragment"><p>En la práctica, esto significa que se agrega un término al coste que es igual a la suma de los cuadrados de los coeficientes multiplicados por un parámetro de regularización.</p></li>
</ul>
<div>
<p><span class="math display">\[J(w) = \text{Costo base sin regularización} + \lambda \sum_{i=1}^{n} w_i^2\]</span> al igual que en L1, <span class="math inline">\(\lambda\)</span> es el parámetro de regularización y <span class="math inline">\(w_i\)</span> son los parámetros del modelo.</p>
</div>
</section><section class="slide level2"><h3 data-number="7.4.3" id="dropout">
<span class="header-section-number">7.4.3</span> Dropout</h3>
<ul>
<li class="fragment"><p>El dropout es una técnica de regularización utilizada principalmente en redes neuronales. Durante el entrenamiento, algunas unidades (neuronas) se “apagan” aleatoriamente, es decir, se les asigna cero, lo que obliga a la red a aprender patrones redundantes que son útiles para la predicción y, por tanto, a ser menos sensible a pesos específicos de neuronas individuales.</p></li>
<li class="fragment"><p>Esta técnica ayuda a que la red se vuelva menos dependiente de cualquier camino único, y así mejora la generalización.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/dropout.png" class="quarto-figure quarto-figure-center" height="400"></p>
</figure>
</div>
</section><section class="slide level2"><h3 data-number="7.4.4" id="aumento-de-datos-data-augmentation">
<span class="header-section-number">7.4.4</span> Aumento de Datos (Data Augmentation)</h3>
<ul>
<li class="fragment"><p>En el contexto de visión por computadora o procesamiento de lenguaje natural, la ampliación de datos implica generar datos de entrenamiento adicionales a partir de los datos existentes mediante la aplicación de una serie de transformaciones aleatorias que producen imágenes o textos plausiblemente reales.</p></li>
<li class="fragment"><p>Esto no solo expande el conjunto de entrenamiento sino que también ayuda a la red a aprender a ser invariante a estas transformaciones, lo que resulta en un modelo más robusto y generalizable.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/data_augmentation.png" class="quarto-figure quarto-figure-center" height="400"></p>
</figure>
</div>
</section><section class="slide level2"><h3 data-number="7.4.5" id="detención-temprana-early-stopping">
<span class="header-section-number">7.4.5</span> Detención Temprana (Early Stopping)</h3>
<ul>
<li class="fragment"><p>La detención temprana implica monitorear el rendimiento del modelo en un conjunto de validación separado durante el entrenamiento y detener el entrenamiento una vez que el rendimiento deje de mejorar.</p></li>
<li class="fragment"><p>Esto evita que el modelo continúe aprendiendo detalles del conjunto de entrenamiento que no se generalizan bien, lo que puede suceder si se entrena durante demasiado tiempo o con demasiados datos. Es una forma de regularización temporal ya que limita la cantidad de entrenamiento que recibe el modelo.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure><p><img data-src="images/02_DNN/early_stopping.jpg" class="quarto-figure quarto-figure-center" height="400"></p>
</figure>
</div>
</section></section><section><section id="extra-visualización-de-redes-neuronales-mlp" class="title-slide slide level1 center" data-background-color="#00A499" data-number="8"><h1>
<span class="header-section-number">8</span> Extra: Visualización de Redes Neuronales MLP</h1>

</section><section class="slide level2">
<img data-src="images/02_DNN/playground.png" class="r-stretch quarto-figure-center"><p class="caption"><a href="http://playground.tensorflow.org">Playground Tensorflow</a> es un sitio web que permite visualizar redes neuronales del tipo MLP</p></section></section><section id="referencias" class="title-slide slide level1 smaller scrollable" data-number="9"><h1>
<span class="header-section-number">9</span> Referencias</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, y Aaron Courville. 2016. <em>Deep learning</em>. MIT press.
</div>
<div id="ref-Hornik1989" class="csl-entry" role="listitem">
Hornik, Kurt, Maxwell Stinchcombe, y Halbert White. 1989. <span>«Multilayer feedforward networks are universal approximators»</span>. <em>Neural networks</em> 2 (5): 359-66.
</div>
</div>
<div class="quarto-auto-generated-content">
<p><img src="images/Usach_P2.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section>
</div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="Deep_Learning_02_files/libs/revealjs/dist/reveal.js"></script><!-- reveal.js plugins --><script src="Deep_Learning_02_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/menu.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/multiplex/socket.io.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/multiplex/multiplex.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/quarto-support/support.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/notes/notes.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/search/search.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/zoom/zoom.js"></script><script src="Deep_Learning_02_files/libs/revealjs/plugin/math/math.js"></script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'multiplex': {"secret":null,"id":"2b17915f5b5a749b","url":"https://reveal-multiplex.glitch.me/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script><script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }
    
        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();
    
          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }
    
        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }
    
      })();
    </script><script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copiado");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copiado");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>


</body></html>